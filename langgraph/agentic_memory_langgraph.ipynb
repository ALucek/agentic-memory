{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1149ac04-be44-4abb-8214-973a06cdde7c",
   "metadata": {},
   "source": [
    "# Agentic Memory - LangGraph Setup\n",
    "\n",
    "Porting the Agentic Memory notebook over from hypothetical to graph-based LLM agent via LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b4770-fe9c-4d3e-95d2-a61628ecdc7b",
   "metadata": {},
   "source": [
    "**Dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e540bb9-8515-4fa9-8142-e14398752cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "import weaviate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a07b9f-6a99-40cd-9a6d-ef2738def35a",
   "metadata": {},
   "source": [
    "**Connecting to Weviate - Vector Database Instance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea1c03f5-b1b5-4bb9-a635-cb9bf2201cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Weviate:  True\n"
     ]
    }
   ],
   "source": [
    "vdb_client = weaviate.connect_to_local()\n",
    "print(\"Connected to Weviate: \", vdb_client.is_ready())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d23faa0-2334-4217-bf94-ebb7790e025b",
   "metadata": {},
   "source": [
    "**Instantiating the LLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b4c668-241f-47a0-bf6d-fe2c337c00bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c745401-da1a-4eec-b271-5ba8f1183a18",
   "metadata": {},
   "source": [
    "**Helper Functions from Before**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2d02904-4b92-4296-b559-6ac3aba90301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Reflection Prompt Chain =========\n",
    "\n",
    "reflection_prompt_template = \"\"\"\n",
    "You are analyzing conversations about research papers to create memories that will help guide future interactions. Your task is to extract key elements that would be most helpful when encountering similar academic discussions in the future.\n",
    "\n",
    "Review the conversation and create a memory reflection following these rules:\n",
    "\n",
    "1. For any field where you don't have enough information or the field isn't relevant, use \"N/A\"\n",
    "2. Be extremely concise - each string should be one clear, actionable sentence\n",
    "3. Focus only on information that would be useful for handling similar future conversations\n",
    "4. Context_tags should be specific enough to match similar situations but general enough to be reusable\n",
    "\n",
    "Output valid JSON in exactly this format:\n",
    "{{\n",
    "    \"context_tags\": [              // 2-4 keywords that would help identify similar future conversations\n",
    "        string,                    // Use field-specific terms like \"deep_learning\", \"methodology_question\", \"results_interpretation\"\n",
    "        ...\n",
    "    ],\n",
    "    \"conversation_summary\": string, // One sentence describing what the conversation accomplished\n",
    "    \"what_worked\": string,         // Most effective approach or strategy used in this conversation\n",
    "    \"what_to_avoid\": string        // Most important pitfall or ineffective approach to avoid\n",
    "}}\n",
    "\n",
    "Examples:\n",
    "- Good context_tags: [\"transformer_architecture\", \"attention_mechanism\", \"methodology_comparison\"]\n",
    "- Bad context_tags: [\"machine_learning\", \"paper_discussion\", \"questions\"]\n",
    "\n",
    "- Good conversation_summary: \"Explained how the attention mechanism in the BERT paper differs from traditional transformer architectures\"\n",
    "- Bad conversation_summary: \"Discussed a machine learning paper\"\n",
    "\n",
    "- Good what_worked: \"Using analogies from matrix multiplication to explain attention score calculations\"\n",
    "- Bad what_worked: \"Explained the technical concepts well\"\n",
    "\n",
    "- Good what_to_avoid: \"Diving into mathematical formulas before establishing user's familiarity with linear algebra fundamentals\"\n",
    "- Bad what_to_avoid: \"Used complicated language\"\n",
    "\n",
    "Additional examples for different research scenarios:\n",
    "\n",
    "Context tags examples:\n",
    "- [\"experimental_design\", \"control_groups\", \"methodology_critique\"]\n",
    "- [\"statistical_significance\", \"p_value_interpretation\", \"sample_size\"]\n",
    "- [\"research_limitations\", \"future_work\", \"methodology_gaps\"]\n",
    "\n",
    "Conversation summary examples:\n",
    "- \"Clarified why the paper's cross-validation approach was more robust than traditional hold-out methods\"\n",
    "- \"Helped identify potential confounding variables in the study's experimental design\"\n",
    "\n",
    "What worked examples:\n",
    "- \"Breaking down complex statistical concepts using visual analogies and real-world examples\"\n",
    "- \"Connecting the paper's methodology to similar approaches in related seminal papers\"\n",
    "\n",
    "What to avoid examples:\n",
    "- \"Assuming familiarity with domain-specific jargon without first checking understanding\"\n",
    "- \"Over-focusing on mathematical proofs when the user needed intuitive understanding\"\n",
    "\n",
    "Do not include any text outside the JSON object in your response.\n",
    "\n",
    "Here is the prior conversation:\n",
    "\n",
    "{conversation}\n",
    "\"\"\"\n",
    "\n",
    "reflection_prompt = ChatPromptTemplate.from_template(reflection_prompt_template)\n",
    "\n",
    "reflection_llm = ChatOpenAI(temperature=0.7, model=\"gpt-4o\")\n",
    "\n",
    "reflect = reflection_prompt | reflection_llm | JsonOutputParser()\n",
    "\n",
    "# ========= Format Conversation Helper ========= \n",
    "\n",
    "def format_conversation(messages):\n",
    "    \n",
    "    # Create an empty list placeholder\n",
    "    conversation = []\n",
    "    \n",
    "    # Start from index 1 to skip the first system message\n",
    "    for message in messages:\n",
    "        conversation.append(f\"{message.type.upper()}: {message.content}\")\n",
    "    \n",
    "    # Join with newlines\n",
    "    return \"\\n\".join(conversation)\n",
    "\n",
    "# ========= Retrieval Functions =========\n",
    "\n",
    "# Episodic Collection Retrieval\n",
    "def episodic_recall(query, vdb_client):\n",
    "    \n",
    "    # Load Database Collection\n",
    "    episodic_memory = vdb_client.collections.get(\"episodic_memory\")\n",
    "\n",
    "    # Hybrid Semantic/BM25 Retrieval\n",
    "    memory = episodic_memory.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,\n",
    "        limit=1,\n",
    "    )\n",
    "    \n",
    "    return memory\n",
    "\n",
    "# Semantic Collection Retrieval\n",
    "def semantic_recall(query, vdb_client):\n",
    "    \n",
    "    # Load Database Collection\n",
    "    coala_collection = vdb_client.collections.get(\"CoALA_Paper\")\n",
    "\n",
    "    # Hybrid Semantic/BM25 Retrieval\n",
    "    memories = coala_collection.query.hybrid(\n",
    "        query=query,\n",
    "        alpha=0.5,\n",
    "        limit=15,\n",
    "    )\n",
    "\n",
    "    combined_text = \"\"\n",
    "    \n",
    "    for i, memory in enumerate(memories.objects):\n",
    "        # Add chunk separator except for first chunk        if i > 0:\n",
    "\n",
    "        \n",
    "        # Add chunk number and content\n",
    "        combined_text += f\"\\nCHUNK {i+1}:\\n\"\n",
    "        combined_text += memory.properties['chunk'].strip()\n",
    "    \n",
    "    return combined_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c2c8a8-865a-41e4-b775-dbb8e58863fd",
   "metadata": {},
   "source": [
    "---\n",
    "## LangGraph Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2efab9-339d-48a2-a584-a33926138b44",
   "metadata": {},
   "source": [
    "**Main State**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "312f304f-d0e6-48ed-aaee-b677ee92466c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: list\n",
    "    semantic_memory: str\n",
    "    procedural_memory: str\n",
    "    prior_conversations: list\n",
    "    what_worked: list\n",
    "    what_to_avoid: list\n",
    "    end: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e550adf-9da4-4fff-8091-0361f67e6be5",
   "metadata": {},
   "source": [
    "**First Node - Populate State**\n",
    "\n",
    "Kicks off the system by populating the state with the initial starting values based on the first message. The back and forth chatting loop relies on having already populated values in the state, so this initial node helps get us there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "08d8dc3e-1452-4675-a288-172626dcdf7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_state(state: State):\n",
    "\n",
    "    # Initial Working Memory\n",
    "    initial_messages = []\n",
    "\n",
    "    # Record down Initial User Query to Start System\n",
    "    first_query = input(\"User: \")\n",
    "    first_message = HumanMessage(first_query)\n",
    "\n",
    "    # Procedural Memory Handling\n",
    "    # Load Persistent Procedural Memory\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"r\") as content:\n",
    "        procedural_memory = content.read()\n",
    "    \n",
    "    # Episodic Memory Handling\n",
    "    # Query Episodic Memory Database\n",
    "    episodic_memory_retrieval = episodic_recall(first_query, vdb_client)\n",
    "    episodic_memory = episodic_memory_retrieval.objects[0].properties\n",
    "    \n",
    "    # Update state lists individually using set operations\n",
    "    prior_conversations = episodic_memory['conversation']\n",
    "    what_worked = episodic_memory['what_worked']\n",
    "    what_to_avoid = episodic_memory['what_to_avoid']\n",
    "    \n",
    "    # episodic_memory_retrieval = episodic_recall(first_query, vdb_client)\n",
    "    # episodic_memory = episodic_memory_retrieval.objects[0].properties\n",
    "    # # Store Initial Variables\n",
    "    # prior_conversations = episodic_memory['conversation']\n",
    "    # what_worked = episodic_memory['what_worked']\n",
    "    # what_to_avoid = episodic_memory['what_to_avoid']\n",
    "\n",
    "    # Create Initial System Prompt with First Episodic Recall and Procedural Memory\n",
    "    episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "    You recall similar conversations with the user, here are the details:\n",
    "    \n",
    "    Current Conversation Match: {prior_conversations}\n",
    "    Previous Conversations: {\"N/A\"}\n",
    "    What has worked well: {what_worked}\n",
    "    What to avoid: {what_to_avoid}\n",
    "    \n",
    "    Use these memories as context for your response to the user.\n",
    "    \n",
    "    Additionally, here are 10 guidelines for interactions with the current user: {procedural_memory}\"\"\"\n",
    "\n",
    "    system_prompt = SystemMessage(episodic_prompt)\n",
    "\n",
    "    # Semantic Memory Handling\n",
    "    # Query Semantic Memory Database\n",
    "    semantic_memory_retrieval = semantic_recall(first_query, vdb_client)\n",
    "    \n",
    "    # Format into Message\n",
    "    semantic_prompt = f\"\"\" If needed, Use this grounded context to factually answer the next question.\n",
    "    Let me know if you do not have enough information or context to answer a question.\n",
    "    \n",
    "    {semantic_memory_retrieval}\n",
    "    \"\"\"\n",
    "    \n",
    "    semantic_message = HumanMessage(semantic_prompt)\n",
    "\n",
    "    # Append To Initial Working Memory with \n",
    "    initial_messages.append(system_prompt)\n",
    "    initial_messages.append(semantic_message)\n",
    "    initial_messages.append(first_message)\n",
    "\n",
    "    return {\"messages\": initial_messages, \n",
    "            \"semantic_memory\": semantic_memory_retrieval,\n",
    "            \"prior_conversations\": [episodic_memory['conversation']], \n",
    "            \"what_worked\": [episodic_memory['what_worked']], \n",
    "            \"what_to_avoid\": [episodic_memory['what_to_avoid']], \n",
    "            \"procedural_memory\": procedural_memory,\n",
    "            \"end\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13702d0c-9b2b-4049-903c-ca7773ae02c0",
   "metadata": {},
   "source": [
    "**Memory Agent Node**\n",
    "\n",
    "Main LLM processing step, takes in messages, passes out to Language Model to generate a response back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0ccd548b-aa0f-4d15-9d83-659574be3d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def memory_agent(state: State):\n",
    "    \n",
    "    messages = state['messages']\n",
    "\n",
    "    response = llm.invoke(messages)\n",
    "\n",
    "    print(\"\\nAI: \", response.content)\n",
    "\n",
    "    messages.append(AIMessage(response.content))\n",
    "\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423401c-4a8f-4492-82e1-73ee7edf8c6b",
   "metadata": {},
   "source": [
    "**User Response Node**\n",
    "\n",
    "This node handles the ongoing conversation as well as subsequent user response. In summary it will\n",
    "1. Load the historical messages, remove the current system prompt and semantic memory recall message\n",
    "2. Take the user's next message\n",
    "3. Create the new System Prompt using the retrieved episodic memory data, along with pre-populated procedural memory data\n",
    "4. Retrieves new context from the Semantic Memory database using the new user message\n",
    "5. Formats the semantic memory context into a user message itself\n",
    "6. Attaches the system prompt, historical messages/working memory, and semantic memory + new user message together\n",
    "7. Returns back to the Memory Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ff85736-3bf4-43aa-bbce-cf7d675b807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_response(state: State):\n",
    "    # Clean System Prompt & Semantic (RAG) Memory\n",
    "    messages = state['messages']\n",
    "    # Remove System Message\n",
    "    messages = messages[1:]\n",
    "    # Remove 3rd to Last Element (semantic context)\n",
    "    messages = messages[:-3] + messages[-2:]\n",
    "    \n",
    "    query = input(\"\\nUser: \")\n",
    "    \n",
    "    if query == \"exit\": \n",
    "        return {\"end\": True}\n",
    "    else: \n",
    "        # Handle Episodic Memory\n",
    "        episodic_memory_retrieval = episodic_recall(query, vdb_client)\n",
    "        episodic_memory = episodic_memory_retrieval.objects[0].properties\n",
    "    \n",
    "        # Update state lists individually using set operations\n",
    "        state_prior_conversations = list(set(state['prior_conversations'] + [episodic_memory['conversation']]))\n",
    "        state_what_worked = list(set(state['what_worked'] + episodic_memory['what_worked'].split('. ')))\n",
    "        state_what_to_avoid = list(set(state['what_to_avoid'] + episodic_memory['what_to_avoid'].split('. ')))\n",
    "        \n",
    "        state_procedural_memory = state['procedural_memory']\n",
    "        \n",
    "        # Create New System Prompt\n",
    "        episodic_prompt = f\"\"\"You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
    "        You recall similar conversations with the user, here are the details:\n",
    "        \n",
    "        Current Conversation Match: {episodic_memory['conversation']}\n",
    "        Previous Conversations: {' | '.join(state_prior_conversations[-3:])}\n",
    "        What has worked well: {state_what_worked}\n",
    "        What to avoid: {state_what_to_avoid}\n",
    "        \n",
    "        Use these memories as context for your response to the user.\n",
    "        \n",
    "        Additionally, here are 10 guidelines for interactions with the current user: {state_procedural_memory}\"\"\"\n",
    "        \n",
    "        # Query Semantic Memory Database\n",
    "        semantic_memory_retrieval = semantic_recall(query, vdb_client)\n",
    "        \n",
    "        # Format into Message\n",
    "        semantic_prompt = f\"\"\" If needed, Use this grounded context to factually answer the next question.\n",
    "        Let me know if you do not have enough information or context to answer a question.\n",
    "        \n",
    "        {semantic_memory_retrieval}\n",
    "        \"\"\"\n",
    "        \n",
    "        semantic_message = HumanMessage(semantic_prompt)\n",
    "        \n",
    "        # Create message objects\n",
    "        system_message = SystemMessage(episodic_prompt)\n",
    "        semantic_message = HumanMessage(semantic_prompt)\n",
    "        user_message = HumanMessage(query)\n",
    "        \n",
    "        # Construct final message list in desired order\n",
    "        final_messages = [system_message]  # Start with system prompt\n",
    "        final_messages.extend(messages)    # Add existing cleaned messages\n",
    "        final_messages.append(semantic_message)  # Add semantic context\n",
    "        final_messages.append(user_message)      # Add user message last\n",
    "        \n",
    "    return {\"messages\": final_messages, \n",
    "            \"semantic_memory\": semantic_memory_retrieval,\n",
    "            \"prior_conversations\": state_prior_conversations, \n",
    "            \"what_worked\": state_what_worked, \n",
    "            \"what_to_avoid\": state_what_to_avoid, \n",
    "            \"procedural_memory\": state_procedural_memory,\n",
    "            \"end\": False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd5c07-260e-44e7-90c8-a74455ca0e8b",
   "metadata": {},
   "source": [
    "**Update Memory Node**\n",
    "\n",
    "If the conversation closes, we undergo a memory update step. In this we remove the system prompt and semantic memory context as before and format the conversation into a string.\n",
    "\n",
    "This is then processed through our existing episodic memory reflection chain to update the episodic database collection in weviate. And then processed through the procedural memory reflection prompt to update the procedural memory file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "030edd09-04cf-451f-bf94-16a7fe71fd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_memory(state: State):\n",
    "\n",
    "    # Clean System Prompt & Semantic (RAG) Memory\n",
    "    messages = state['messages']\n",
    "    # Remove System Message\n",
    "    messages = messages[1:]\n",
    "    # Remove 3rd to Last Element (semantic context)\n",
    "    messages = messages[:-3] + messages[-2:]\n",
    "    \n",
    "    # Update Episodic Memory\n",
    "    conversation = format_conversation(messages)\n",
    "    \n",
    "    # Create Reflection\n",
    "    reflection = reflect.invoke({\"conversation\": conversation})\n",
    "\n",
    "    # Load Database Collection\n",
    "    episodic_memory = vdb_client.collections.get(\"episodic_memory\")\n",
    "\n",
    "    # Insert Entry Into Collection\n",
    "    episodic_memory.data.insert({\n",
    "        \"conversation\": conversation,\n",
    "        \"context_tags\": reflection['context_tags'],\n",
    "        \"conversation_summary\": reflection['conversation_summary'],\n",
    "        \"what_worked\": reflection['what_worked'],\n",
    "        \"what_to_avoid\": reflection['what_to_avoid'],\n",
    "    })\n",
    "    print(\"\\n=== Updated Episodic Memory ===\")\n",
    "\n",
    "    #Updating Procedural Memory\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"r\") as content:\n",
    "        current_takeaways = content.read()\n",
    "\n",
    "    what_worked = state['what_worked']\n",
    "    what_to_avoid = state['what_to_avoid']\n",
    "    \n",
    "    # Load Existing and Gathered Feedback into Prompt\n",
    "    procedural_prompt = f\"\"\"You are maintaining a continuously updated list of the most important procedural behavior instructions for an AI assistant. Your task is to refine and improve a list of key takeaways based on new conversation feedback while maintaining the most valuable existing insights.\n",
    "\n",
    "    CURRENT TAKEAWAYS:\n",
    "    {current_takeaways}\n",
    "\n",
    "    NEW FEEDBACK:\n",
    "    What Worked Well:\n",
    "    {what_worked}\n",
    "\n",
    "    What To Avoid:\n",
    "    {what_to_avoid}\n",
    "\n",
    "    Please generate an updated list of up to 10 key takeaways that combines:\n",
    "    1. The most valuable insights from the current takeaways\n",
    "    2. New learnings from the recent feedback\n",
    "    3. Any synthesized insights combining multiple learnings\n",
    "\n",
    "    Requirements for each takeaway:\n",
    "    - Must be specific and actionable\n",
    "    - Should address a distinct aspect of behavior\n",
    "    - Include a clear rationale\n",
    "    - Written in imperative form (e.g., \"Maintain conversation context by...\")\n",
    "\n",
    "    Format each takeaway as:\n",
    "    [#]. [Instruction] - [Brief rationale]\n",
    "\n",
    "    The final list should:\n",
    "    - Be ordered by importance/impact\n",
    "    - Cover a diverse range of interaction aspects\n",
    "    - Focus on concrete behaviors rather than abstract principles\n",
    "    - Preserve particularly valuable existing takeaways\n",
    "    - Incorporate new insights when they provide meaningful improvements\n",
    "\n",
    "    Return up to but no more than 10 takeaways, replacing or combining existing ones as needed to maintain the most effective set of guidelines.\n",
    "    Return just the list, no preamble or explanation.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate New Procedural Memory\n",
    "    procedural_memory = llm.invoke(procedural_prompt)\n",
    "\n",
    "    # Write to File\n",
    "    with open(\"./langgraph/procedural_memory_lg.txt\", \"w\") as content:\n",
    "        content.write(procedural_memory_lg.content)\n",
    "\n",
    "    print(\"\\n=== Updated Procedural Memory ===\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91ec3e2-91c6-4fd5-959b-307179ee6a24",
   "metadata": {},
   "source": [
    "**Check End Logic Function**\n",
    "\n",
    "Plugs into conditional edges in our graph to handle when the conversation should stop looping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da3c5fd9-63c8-445e-b328-a2a72d62749a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_end(state):\n",
    "    if not state[\"end\"]:\n",
    "        return \"continue\"\n",
    "    else:\n",
    "        return \"stop\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823ced9-7626-49c8-8cf2-17f197cfc570",
   "metadata": {},
   "source": [
    "**Compiling Main Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0f9af3b1-ad3e-4f75-980e-737a2e39f0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "\n",
    "graph_builder.add_node(\"populate_state\", populate_state)\n",
    "graph_builder.add_node(\"memory_agent\", memory_agent)\n",
    "graph_builder.add_node(\"user_response\", user_response)\n",
    "graph_builder.add_node(\"update_memory\", update_memory)\n",
    "\n",
    "\n",
    "graph_builder.add_edge(START, \"populate_state\")\n",
    "graph_builder.add_edge(\"populate_state\", \"memory_agent\")\n",
    "graph_builder.add_edge(\"memory_agent\", \"user_response\")\n",
    "graph_builder.add_conditional_edges(\"user_response\", \n",
    "                             check_end,\n",
    "                             {\n",
    "                                 \"continue\": \"memory_agent\",\n",
    "                                 \"stop\": \"update_memory\",\n",
    "                             })\n",
    "graph_builder.add_edge(\"update_memory\", END)\n",
    "\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d8d480-fa5c-4928-a4cd-a61cfa994d92",
   "metadata": {},
   "source": [
    "**Memory Agent Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fcc7db30-3c90-4b83-9141-b40c6a99c64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKIAAAJDCAIAAAAHF1hCAAAAAXNSR0IArs4c6QAAIABJREFUeJztnXdcE8n7xycFSEihJPSAoIAgihTB3sWCiI1DT1HsXc9653meXTnPep5d7F0RFbFgwYZdEbsoiIpACCWdtE3y+2P95fgqQoBkN2H3/eIPspmdeZJPZmZn95nnIWi1WoDT0CGibQAOEuAyYwJcZkyAy4wJcJkxAS4zJiCjbUAVlBUppEK1VAQpZBqlXIO2OXphSSGSyARrBsmaSXLxpKJtzrcQTGfd/OV9Re5z6cdXUmcvilyqpjHJNmwLrXmoDCypRAFPWSFWQyrt57cVngHWjZvT/cMZBCIBbdOAqchckCu7d67MzsnCgWPlGUBj2lugbVF9yXsp/fBS8ulNRVBn25BudmibYwIyXz/B4xcr2/ZjmeBYV3/upJS+eSDqNdLZvak1imagKbOYrzr6d37kGGeOD5pfgbGRSdXXjhS7+VCDu6DWrVGTWS5VH1ub//Ov7lZUEioGIEzGmVIbB4sW7W1QaR0dmfnFypSdhfF/eiLfNIrcTC4hEECngQ7IN43Ouvno35/jFjRCpWkU6TzIQSXXvH4gQr5pFGROO8iNneNOIpnESgNhuv/sVPBexsuXI9wu0jJnPxETAGC7WiHcrukQ0I55+3Qpwo0iLfPdc6Xt+rERbtSkcG1MtaIS815JkWwUUZlfPxC2aGdDtzXFO6xI0r4/K/sxojM0ojJnP5Y4e1GQaUutVmdlZaF1evXYOVqVfFEKSpRGqv97kJNZpdAUf5Yjdidk+fLlq1atQuv0GvFqTst7idy4jZzMH99Im7VmItacQqGo24nwjYQ6n64nTQJpxfnGbaIyyE2T/GKVFdUov6qMjIx///33y5cvrq6uMTExQ4YMWbJkyZUrVwAArVq1AgCkpKS4urpmZWUlJibCQ3FAQMDMmTP9/f0BAFevXp0/f/7atWsPHjz46tWr+Pj44uLi7083rM1MlkVhjsywdVYDcjJLRZCDEdZRFRUVv/32W+PGjRcuXJiTk1NSUgIAGDNmTHFxcUFBwbJlywAAbDYbAFBYWKhQKMaNG0ckEk+ePDljxoxz585RKF+vFVavXj116tTJkyd7eHjI5fLvTzcsNCa5Qqw2eLU/AkGZhZCnP83g1ZaXlysUim7duvXp00d30MPDw9bWtqysLCgoSHewT58+kZGR8P/NmjWbNGlSVlZWmzZt4CNDhgyJiorSFf7+dINjzSBJRRCNiYQEyMlMIhGIRmjNzc0tMDBw9+7dVCp10KBBlpaWPypJIBCuX79+6NChvLw8a2trAEBZWZnu3fDwcMMbVy1UBkkDIfRAAblLMEsqUSow/DBFIBA2bdoUFRW1cePGQYMGZWZm/qhkYmLivHnzmjVrtn79+pkzZwIANJr/fFNg4ZGknKuk2SDUzZCTmcYkS0WQMWqm0+nz588/deoUnU6fPXt2RUUFfLzywzeFQrF3794BAwbMmTMnKCioRYsWNVZr1Gd3MonaikokInVjHzmZbR0tNGqjfHHw4sfNzW3o0KESiaSwsBAAQKVSy8rKdP1VJpMpFAr40hoAIBAIvunN3/DN6QanQgQh6U+C3Nzs7mt9NyW/dR+WYatVqVSDBw+OiIho0qTJyZMn6XQ6h8MBAISEhKSkpKxatSooKIjJZHbq1Mnb2/vYsWMsFksikezcuZNIJObk5Pyo2u9PN6zZuS+ktmzkXN5IS5YsQaYlSyviu6cSRzcrw05IUqn08+fP169fT09Pd3BwWLJkCSyzt7e3UCi8dOlSZmamra1teHh4SEjInTt3Tpw48enTp+nTpzdq1OjUqVPDhw//9OnT1atXY2NjbW1tddV+f7oBbQYAZJwtDe5qi9jcjKj3SNYNAQDaIPRcokyECjF09Uhx9EQ3xFpE9GFRUBfbLbNzAjvZEn/gvfz48eO5c+d+f5zBYIjF4ipP+eWXXwYOHGhoS/8HiURSeUldmcDAwOfPn39/fMyYMSNHjvxRhffPlzdpSTeojTWAtC/Y0+t8qUjdoX/V95UUCkXltaw+2NjY0GiGv+tSGY1Gw+Vya3UKk8mk06sWUlCiPLezaMQfiPpIoeDyl7KjoGecM4WGCYfO77l9poTjTfVqjmhvRsEXrGus47G1+ci3awo8vlpOJhMR1hgdmRl2Fp1jHE5vKUC+aXR5fV9Y9EHeNsrAS0p9QM0dv+SLPONs2cCpyF1tosure0JevqJrrCMqraO2v9mBQwnpZrt3SZ5EaJQ7oCbFnZTSoo9ytDRGf6ucRACln+Ax7cntotiWlAa4p/7tI9Hdc2UhPeyCOtnqUdxYoL8jEgDwIkN4N7U0pKutS2Nqw9g2JypTfXgpzXkmsWFZtOvHQuahcjWYhMwwL+8K3z+V8D7Lm7e30WoB3YbMsCMTzGRzBolEEPNVUiGklGvy38lUSk3j5rRmbZgsF5PYeGBCMsMoFZr8t1JROSQRQpBSa3BPGqFQWFJS4u3tbdhqGbYWarWGZkOm25KdPKxMRF0dJiezscnIyEhKStq4cSPahiBKA7zqwfkeXGZMgDmZyWSyk5MT2lYgDeZkhiCouLgYbSuQBnMyEwgEnQs+dsCczFqtVi5HOlgA6mBOZiKRyGQit2PPRMCczBqNRiRCIcgLumBOZjKZ7OLigrYVSIM5mSEIKioqQtsKpMGczNgEczITiURje4KaIJiTWaPRSKWIBmsyBTAnM5FI/JEHdQMGczJrNBqJRIK2FUiDOZmxCeZkJpFIxggZY+JgTma1Wl1ainRkVNTBnMzYBHMyk8lkZ2dntK1AGszJDEFQbXexNgAwJzM2wZzM+BMqTIA/ocJpsGBOZtyBFxPgDrw4DRbMyYz7aWMC3E8bE5BIJAcHFJJxogvmZFar1XA+DEyBOZmxCeZkxjfXYAJ8cw0mwJ83YwL8eTMmwB9EYgL8QSQmIBKJlVOXYASshH8bPHiwSqUCAMjlcplMZmdnByengjO7NnhQDhmKGO3btz98+DCB8DUCqEwmAwD4+vqibRdCYGXQHjFihJvb/4Rop1Ao/fv3R88iRMGKzA4ODl26dKk8Q7m5uUVHR6NqFHJgReZvOjSFQhk4cCCVSkXbKITAkMwODg69e/eG/3dxccHOiI0tmQEAMTExHh4eZDI5OjoaO1251lfaakjLL1aK+UglETc8tO5thz1+/Lh1i+gPL801NIWlFZHtalmrfG21WDdn3RS8fSTWqLUsV4qiwvB51XH0xJJCzM+WcnypPeOcSWS9kkToK/Ojy+X8EqhtFGopdnC+oSiv4nFa6eAZblbUmru1XnNz1g0Bn6fCNTYpXLysO8U4n9jwRZ/CNcushrRvH4va9sPcTgXTx4Zt6dmM/uqesMaSNcvML1Zq8InYVLFmkos/K2osVrPMYj7EcsWc/7q5wGRbKmSaGovVLLMWAPy62mTRqoFcWrM62Lo9gllwmTEBLjMmwGXGBLjMmACXGRPgMmMCXGZMgMuMCXCZMQEuMyYwb5n/2bR6UExPfUpKJJJ3798aw4Za1czlFhVxC41hRvWYt8z6M27C0IsXz6Jbc0Hhl2Fx0dnZr41hRvVgRWalUol6zWoIQmvHmlH2UC1cNOdjXq6Pj9/jJ/cJBGLr1u2nTJplZ2cP7zvdu2972uVUoVDQqJHXqPiJHdp3AQC8z8meMHF4z559X79+UVxcxOF4DPt5dI/uvQEAu/dsPX7i4OVL9+DK32a/njxl5F8Jm1qHt/um3YuXUs6cOfEhL4dKtQ4Paztt6lxbWzsAwNBhUXx++ZmzJ8+cPenk5HzsSCq8Zy5x95Zr6ZeUSoU7p1Fs7IhuXWsY/48c3Xfm7AmxWOTt3XRU/MTQkPDva1YqlQcO7kpPT+OVFLNY7J4RfUfFTySRSEXcwvjRMQCApcvmLwWgV6+o+b8uAQAUcQu3bl3/JPOBpaWVr4/fmDFT/Jo2M7gixtoqV1LKi46OiY0d8e7dm917tn7My9229QCZTF67bsXVaxfjho/x9Gxy9drFPxfN/WfDrsDAYPgsLrdw9qwFEASlpCStXLWQTCZ36dxD/0Zfv37h4eEZERHJ55cnnz4mrZAmrNwIAFiy+O9ff5sW1DL0p5jhFpaWcASSPxbO4nILhw8bbWtrn5X1ePmKBXK5LLLPD330n2Q+3JW4uXv33q3D2j18dFdWUVFlzSQS6cmTB23bdXJ14eTkZB86vIfBYMb+FMeyZ/+xYMXKVQtHj5oUHNQK/tGXlZVOnzHGzc192tS5BALh8uXzv8wct33rQS+vJvWXoDLGktmzUePYn+IAAP5+ATQafeWqhQ8f3uVwPNIup44cMW5U/EQAQOdO3eNGDty3f8f6ddvhs4bGjgwOagUACA0JHz029ujRfbWSefasBbo9j2Qy+dDhPQqFwsrKyq9pMzKZzGKxW7QIgt+9dTv9+YunRw+fY7MdAAA9uveWySpOJR+tRmYutxAAMLB/bEBAYEREJHzw+5pJJNLWLft1ZhQWfbl1Oz32pzhLS0tfHz8AgIeHp67wwUOJdrb269ZsI5PJAICIHpFxIwekXjg9ferc2n/l1YHExtfw8HYAgDdvX5aVlwIAOnToCh8nEAhhrdpcuXrh+1OIRGKrVm1Onz4Ob0rWE5VKlXz62JWrF3g8rpUVRaPRCAR8J6cqAsrcv58BQdCwuP+2yqnVahqtuqSCbVp3YDCYqxL+nD5tXps2HaopyeeXHzi469Hj+2KxCADAoDN+VPLBgzu8kuLIqI6VP0IJz/ABgpGQmU6jEwiEClmFVCoBANjZ2uveYjJtKioqqszNyaAztFqtTC7TsxWtVrvgj5nZ717Hj5zQrFng7dvpx44f0Gir9pPi88tYLPb6tdsrHySRq/s2WCz25k17tmxb//sfM5s3b7loYYKDQxUezeXlZRMmDadSrceMnuzqytmzZ2v+l08/qrOcX9a2bccJ46ZXPlj9r61uICFzaWmJVqt1dHBisRwAACKREB4q4S+FTCZXGRK3pIRHoVCYDKZuAKyeZ88yn2Q+/GPBCvjCreDL528KVL7KZTCYAgHfycnFyspK/w/i4eG5OmFT5tNHixbPXf33krVrtn5fc8q5U3x++ZZ/98GjiKOjczUyMxhMoVDg4eGpvw11A4kF1YWLZwEAAc0C/f2bEwiE+w8y4ONKpfL+g4yAgEAS6dt9A2KJ+Pbt9OYBLQEANjZ2KpVKKPrqjcytdHvBwsJSJquAIAgAIBQJAADw/Kd7qdF87c1UCrWs7L9kciEh4Wq1OuVcku4IHL+geuC1U0hwWJs2HXW3RL6pWSQS2Nra6WYKoUig+xFYWVEAAGWl/0UMDQkJf/nyWfa7N7Uyow6QlixZUn0JPk/Fy1d4Nf/hBPM96dcvv3r1XC6X83jcM2dOJJ060rp1+2E/j2IymFxu0ekzxwEglJaWbNu2Ie9j7ry5i1xc3MrLy86lJhdxCzUazbNnT9avX1nOL1/w+3IHByeaNe1sSlJpKc/JyeXJ4wdbt62Xy2U9evThuLkLBPzrN658yHvftGmAs5Pr2ZSTxcVF1ta0W7fTDx5KVKlUwUGt4L7y/n327Yx0Mpn88dMHC7JFcHDYo8f30y6nCkUCPr/8Ulrqv5v/juo7iPzjcfvN21czZ42HICj3w/vU1GS/ps3gC7Fvaram0S5eTNFo1EqV6tix/TdvXZNKpQP6/0ShUGg02pUrF168yrK2pj158sDXx9/X1//K1QtXrlxQq9X5Xz4dPrzn5u1r3br20v+rlvChknyZf3gN4SmNJXNFhVShUFy4eKaoqKBnRN9Zv/xuaWkJAAhr1VYqlVy8dDY9PY1mTZs7Z2FYWFt49D6Xmuzl5Z2Rcf3O3ZtOTi5zZi8MDm4FALC1tXNxdrt27WLy6WMVFdKfYoZn3LkBy+zl1UQulz16dM+/aYCfX4CnZ+NLaecupZ2DIOiPBStKS3kvX2b16hUFAAgICMzJyb5y9cL792/9/AK8vJp06RwhkYhu3Lhy63a6tELSp3f/Fi2CiMQfDm8ioTA3993165czMx+2bBkya+YCeBL9puZOHbtptZozZ0/evnXN1c197pw/X7x4KpNVBAW1IhAIzZoFPnx0N/16WhG3sEP7rq4ubu3bdf70Oe/KlfOPHt+j0eh9Iwd4ejbW/6vWU+aat8p9eCl9eUfUdWgtQqYtXDSnhFe8Y/sh/U+Bb4+sWrGhbduOehTH+UrRB9mru+UDp7pVXwwrkYT0ZFfi5soTtg4mw+bwIaPcEkcGXOb/ITZ2RFTUoO+PEwnmffPfKDKvWLautqf4eDe9fu2xMYypFTZMGxumDdpWGB7z/pHi6AkuMybAZcYEuMyYAJcZE+AyYwJcZkyAy4wJcJkxAS4zJqhZZgsLYM3Eb32bKFoAbNgWNRarWWZ7F6tPryUGsgrHwJR8kVHphojZSWOSnTwowhJj7VrAqQ/CEqVnM+sai+k1N3eOYV8/UaTRmG0U7QbK3XM8tquli1fN8d/1DbQsEUD7l31sE+XAsLdgsiwBrjh6QCpNyRd5wXupa2NKSDc7fU6pXbqxBxfLCnLlGrVWIoDqYSeaaDQaNQTBG2HMFHtnKyqd6NeK4d605uEaBitZ5XRkZGQkJSVt3LgRbUMQBV83YwJcZkyAOZnx/M2YAM/fjAlIJBKbzUbbCqTBnMxqtbq0tFSPgg0KzMlMJpOdnDCXhQdzMkMQVFxs+HAAJg7mZMbnZkyAz804DRbMyUwikRwdMZfsEnMyq9VqHo+HthVIgzmZsQnmZCYQCBYWNfvINTAwJ7NWq61V5MCGAeZkJhAIVUaba9hgTmatViuXy9G2AmkwJzM2wZzMRCLR1tYWbSuQBnMyazQagUCAthVIgzmZsQnmZCaRSA4ODmhbgTSYk1mtVpeUlOhRsEGBOZmxCeZkxh14MQHuwIvTYMGczLgvGCbAfcEwAYFAoFJr3t7fwMCczFqt1khJgEwZzMmMTTAnM765BhPgm2swAZlMdnauIgdswwZzMkMQxOVy0bYCaTAnMz43YwJ8bsYE2JybsRL+bdSoUVqtFnYEk0gkHh4eGo1GKpUmJyejbRoSYCVQNofDuXjxoi6x+6tXrwAA7u7uaNuFEFgZtOPj47+58iISiREREehZhChYkdnHxyc8PLzyDMXhcGJiYlA1CjmwIjMAIC4uTtehCQRC165dsbOfHUMye3t7h4WFwf97eHjExsaibRFyYEhmAMCIESPgDt25c2dM3SSpy5W2UqZRyDVGMMboOLE8w0M6v3jxIjpyiJhvlpHfCQRAt621arVbNz+9wX9+W0ggEDRqTKy2TRC2m1Vhrsy7Jb3jQLaFlb6DcS1kvpFUotECvzBbhh3mgjqYFEq5upyrvHqoYPQSLwqt5uxEtZD52jGelTWpZWdWvY3EMRj7l+RMXd9Ed8+nGvTq9V/eV2g0ANfY1Og+zOX2Gb28VPWSuaRAQSJj65rcLGCyLD69qtCnpF7iySRqtotVva3CMTBMlqU1k6zW43JYL5nlUo0Kwi+tTRHuJ5nB5mYccweXGRPgMmMCXGZMgMuMCXCZMQEuMybAZcYEuMyYAJcZE+AyYwJcZpOAyy0q4hYar35cZvQpKPwyLC46O/u18ZrAisxG3Sqm1WoLCr/U+XQ1BBl7J5ux9lD1699l+tR5166nPX36iE5n9OjeJzAweO++7V++fPbybDJr1oKmvv5wyadZj3clbs7NfWdnZx8cFDZu7FQWi12rGi5fPn/46N7Cwi8sFrtv5MDhw0YTiUShUDBgUI9JE395n5N9584NHx8/ihVFJBJu33ZQZ+TQYVHBQWG//br4R5/ixYusg4cSX7zMAgD4NQ2YNGmmrtHXb15u2bruw4f3LHu2p1eTnJzsA/uSLS0t5XJ54u4t19IvKZUKd06j2NgR3br2BAAknTqSfv3yTzHDd+/eUlZe6uPjN3f2Qg8PzyJuYfzoGADA0mXzlwLQq1fU/F+XGFwOI/bmdRtWtmvb6Z+NiYEtgk8mHd74z1/jxkz9K2GTTC5buvQ3CIIAAE8yH/762zTPRo3nzvkzNibu+fPM2XMn6VKO6FNDWlpqwurFPj5+fy5c1aVzxJ692w4f2auz4dCh3c5OLuvWbp86ZU6fPv2z3735+PED/NabNy+Li7ndu/eu5iNwuYUKpWJE3Lj4kRO43ML5v8+AbSsu5s6dN5lMJv/x+4rg4LA7d25G94uxtLTUaDR/LJx1796t4cNGz5q5wNu76fIVCy5cPKtr8cSJg3PmLFy2dG0Jrzhh9WIAAMue/ceCFQCA0aMmbdqYGDdsjFHE0OrBtWPFj9OFIoFW/7/OnTsvW5oA/5/9tiA0NHT/vuPwy6QTqaGhoS+f54kE2kGDYlYsX6076+XzvNDQ0POp6XrWIORrevXqPWrUWF0Nfy5c1rFjR26hNP8TPzQ0dPKkabq3SnmKLp27rPn7H/jl6r82RET05JdB1XwKIV+j+//mjUehoaHXrt4TCbRbt+wODQ39+KEULjNgwCDYhpSzV1q3bv0hh6c7a97c33/6aYhIoN2z+7DuFJFAuzvxUGhoaP5nge5Tp5y9UqtvGP7bPPu9Wl2zgkbc+Gpl9TXdk6WFJQDA0tISfung6AQAEAoFXG7Rp095BQX5qedPVz6RxyvWswYCgVBaWjIkdoTu3LCwthcunv1S8NnJ0RkAEBISrnvL0tKye/feV65eGDd2KolEunnrapcuESRSdQ6wBALhdsb1EycPffqUZ21tDQDgl5cBAEpKimk0mr09Cy7j6sopLi4CANy/nwFB0LC4aF0NarWaRqPrXlIoXwMMOjm5AADKSktsmDZ1/YJrAZr7m/n8MgBA/MgJnTp2q3zc3l7f0KkSqQQAYGtrrzvCYDABAKUlPFhm3dcK07t39JmzJ59kPqTTGcXF3O7dqhuxAQAHDibu3bd98KCfJ4ybXlZeunTZfI1WAwBwc3OXSqUfPuQ0buytUqlycrKDglrBn4jFYq9fu71yJSRyFV+yBdkCAKDWqPX8pPUETZnpdAYAQKGQe3h41q0GR4ev3Vp3hM8v14n9PU19/Rs39k5LO8dmO7q6cpr5N6+mcoVCceTo3r6RA6ZNnVN5jAEA9OoZdTLp8IKFM3tG9M169gSCoFEjJ8DtCgR8JycXKyvT8pBEc0HF4Xg4OTlfvJSiC6IJQVCtEjiyWGxnJ5eHD+/ojty8eZVCoXh7N/3RKX16R2fcuXH9xuUe1V58AQDkcplCofD9/0troUgA5zcCANjY2E6bOtfKipKXl9sqtM2uHUc4HA94jlCr1SnnknSV6BMfFJ6bykqNmIEDzd5MIBCmTpmzaPG8qdNHRfeL0ajVaZdTIyIiYwYP07+SUfET//p7yZq1y8PC2mZmPsy4cyN+5AQqlapUKqos361rry1b15eU8GocsW1sbBs39k4+fczeniWVSPYf2EkkEj98yAEAvHn76u81S2dM+5VsYUEkEouKCuztWSQSKaJH5LnU5O07/iniFvr6+OXkvMu4c33fnqTqs1I6Ojq5uridSDpEoVJFIuHgQT/rrkIMBcqxRzp26JqwcuPefdu3bF1Ho9EDWwQHBobUqoZevaLkCvnJpMOXr5xnsxwmjJ8+dMjIasrb27NcnF3pdIY+M8Wff6xa/feSZct/53A8Jk+elZv77tSpoxMnzHB2cnFxcVu9ZqnutoaPd9NN/+ymUChrVm/Zlfhvenpaamoyh+MR3S+GXNXcXBkCgbBw4aq/1yzdvGWto6Nz9269HR0NvClXrz1U6cd5No4U35CqJzzzQi6Xj4gfGDN4WOXr8zqgVqvhq3S1Wn074/rSZfPXrd0WEhxmOEv14sCynMlrvIk1zb1YiSQE63H02P7062kqlap3769rHolE8vPwqCrLT5zwS1TfgVW+9fnzx19mjW/bpqN3E1+FUnHr1jUKhcJx8zCm+fUCWzIfP34gODhs2dK1utWqtbX1zh1HqizPZPxwRUuj0bt3633//u0rVy/Q6YwWzYNmzvzd4COtAcHcoN3A0HPQxsoTKoyDy4wJcJkxAS4zJsBlxgS4zJgAlxkT4DJjAlxmTIDLjAn0kplKI5Etag5Xg4M8Lp5UfW5X6yWzNZNU+kVuCKtwDImgRFkhgUgkAwWMcvKwglRmGVm5YSMoUXoF0PQpqZfMzp5UGoP06JIRnZVwaou8Aso4zW0frZcXbC0CLT9MKy8vVjZtZctytdInshyOkRDzVYJixc2k4nErvSws9eqotQub/vaR6PltoVQIqZQmGttRo9UCoCUS6ruC0AJgmj9kp0ZUQYmiSSC9Q399vdnrmlVOC0w2CcLAgQP37NljZ2dX5xqKiopmzpxJIpEWLVrk5+dnUOsMAAEAS2qtf8R1chIiAKvat4QA58+fbxXe0tm1XnG/1Vo5pJF9KeQuWDhv0qRJ/fr1M5yBqGGKatWZgwcPjhhRL39NeEsAvNeyuLh406ZN69evN5B1aNJwZH7w4IG9vb2Pj08961GpVLoLTD6ff+rUqV9++cUQBqJJw5F5//798fHx9a9HqVTCO2hgFArF3bt3f/755/rXjCINROacnBxra+vWrVvXvyqZTAYP2jBardbS0lKpVNa/ZhRpIH7aBw4c6Nq1q0GqUigUarUa3hVHp9Nv3bplkGrRpSH05vLy8nv37vXt29cgtXXr1k2lUjGZzMzMzOHDh+/cudMg1aJLQ8jGvm/fPhqN9tNPPxm8Zrlc/uuvv27atMngNSNMQ5C5Xbt2169fN7Wd4yaF2Q/ap0+fjoyMNJ7GZWVlGzZsMFLliGH2Mj948GD48OHGq5/FYn38+DEjI8N4TSCAeV9pP3/+vLi42MvLy6itrFy5srRUrxx9Jot5y5ycnDxo0CBjt0Kn0+l0uh4FTRczHrQhCHrw4AEyjxauXLly5EjV26DNAjOWOSUlpUOHDsi01bFjx927dyPTljEwY5nPnz9vqFsiNUJiviKdAAAgAElEQVShUK5du4ZMW8bAXGUuLCzk8XhBQUGItSiTyYqLi/UoaIqYq8zp6ekxMTFItkilUmNjYyUSCZKNGgpzlfnChQtt2rRBuNG4uLgHDx4g3KhBMMsFFZfLFQqFTZv+MGKjkRg/fjzCLRoKs+zNN2/e7Ny5MypNP336tLLTgblgljJnZmZ269ZNj4KG5/Dhwzdv3kSl6fpgljJfu3atVatWqDQ9dOhQkUiEStP1wfzm5szMzODgYH1KQhBk8AE2MDAwMDAQXZ+hOsTnNUuZQ0L0itIrkUiMoYdCoUD32TabzSbWGNfvfzG/QVt/mY2EQqEwOw9A85OZx+O1bNkSRQOqj4FumpjZoM3lcmUyGbpftMFD1yOAmfXm3NzcJk2aoGuDVqtVKKrOsGCymJnMeXl5xvYVqRECgSAWi+FNVlwut/Jb69evN82dOGYms1AoDAgIQNsKYG1tXVhYOGbMmPfv339znEql/vg81DCzufn9+/eBgYFoWwGsra3Lysq+932eNGkSShbVgJnJLBAIbG1t61NDWlpaSkrKly9faDRa69atR44caWdnB0HQoUOHrl69KhKJ3N3d4+Li2rZtCwA4c+bMzZs3Bw4cuH//fj6f36RJkxkzZri7u+fn50+cOBEAkJCQkJCQ0KNHj9mzZ48aNYrH4zVr1mzt2rUAgGXLlnE4HBKJdOnSJQiCwsLCpk6dSqPRIAiKjo4eNWpUbGwsbNKSJUuEQiHsJiyXy/fv33/jxg2lUsnhcAYNGmSQu/dmNmjXU+ZDhw79888/HA5n+vTpgwYN4nK5FhYWAIBNmzadOnWqd+/e8+bNc3JyWr58+cuXL+FTsrOzk5OTZ8yYsXDhwtLSUni7s7W19ezZswEAI0aMWLNmzZAhQwAAM2bM+ObyMDk5ubi4eMmSJRMnTszIyDh27Fj15mk0mqVLlz548GDIkCHTp09v3Ljx6tWr09LS6vx5dZhZb1YqlXWWubS09Pjx4926dZs7dy58BHZMyM/Pv3r16s8//xwXFwcA6NChw7hx4w4fPpyQkAAXW7x4MRzlIjo6eteuXSKRiE6ne3t7AwA4HI7uWiEkJCQ5OVmXlRgA4ObmNm/ePAKB0LRp0zt37jx58mTs2LHVWHjnzp1Xr17t3buXxWIBALp06SKXy8+ePdurV6+6fWQdZiazWCyuPkdrNTx9+lStVn/vPgZ33Hbt2sEvCQRCSEhIenq6roBume7o6Ajvw/Dy8tLHDCur/0IuOTk5vXnzpvryjx49giBozJj/Ujir1WoaTa/IX9VjZjLDW43hHLu1hc/nwzeEvzkulUoBAJUHCQaDIZPJKioqvikJ54fTaDQqlaq2D0XIZDK8n7Z6C+3t7XWjSOVG64mZyWxhYVGrXKGVgV3q+Xy+g4ND5ePwCCkWi+F/4DJkMrma5xMymaxGzX5ENSHV6HS6UCh0dHQ0+KMRM7sEs7KyqvMdKHglVvmKBo5K4OfnRyAQHj58CB9UKpWPHj3y9/evZli2tLSE18dlZWW1NYNEIjEYjPLycvilVqvl8Xjw/0FBQWq1+sKFC7rC+iSM1Qcz681Nmzat89MhDofTu3fvixcvisXikJAQkUh08eLFhIQEFxeXHj16HD58WKPRODs7p6Wl8fl83WValVAoFGdnZ2dn59OnT1MoFLFYHB0drX8XDAkJuXbtWsuWLe3s7JKTk798+QJfonfr1u3SpUu7d+8uLi5u0qTJhw8f7t27t3379vrfwzczmSEIys/Pb9y4cd1OnzZtmpOT06VLl+7fv89isUJCQuCZb8qUKdbW1ikpKRKJpFGjRosXL67eA1wul1MolN9++23jxo07duxwdHTs1KmTk5O+yQMnTJigVCrXrVtHo9EiIyMVCgXskWJhYbFixYq9e/fevHnz4sWLrq6ukZGRBpmbzWwb+7p161xcXIYN0yvBs0AgMMaDYY1GIxAI7O3tDV6znjR8twI3N7eCggK0rQB1u9RHETOT2cPDA/Xhh0gkmp1ngZnJ7Ovri/qWNaVSWTlwmFlgZjKz2WwymfzNU16EqaioMLtw4mYmMwAgICDg1atXKBpgZWVV5xuuaGFmCyoAQFhY2JcvX/QpaW1tbYxJlMk0v3TlZragAgC8fft2+fLlhw8fRqX1jIwMOp2O5L5qg2B+g7afnx+Px9PdLESYTZs2MRgMVJquD+YnMwCgbdu29+7dQ75duVweHx+PumtpHTBLmbt27ZqTk4N8uxQKBbFoJ4bFLGXu3LnzoUOHkG9306ZN37hymgtmKTORSOzatSvC90kEAsHZs2frn2QBFcxSZgBAr169DOILpz9arRaty/v6Y34LKh0dO3a8du2aOe5oQh5z7c0AgH79+p0+fRqZtrhc7owZM5BpyxiYscwDBgw4c+YMMm0lJSXpGSLBNDG/m506fH193dzc3rx54+/vb+y2xo0bZ9bR9824N8POUwgExq2oqBCJRGb3VKoy5i1zZGTkrVu3jB1gce7cuXl5eUZtwtiYt8xwgMWjR48ar34ej+fo6GiQRGYoYsYLKhiZTBYREWHuuSiMjdn3ZiqVGhcXd/78eSPVb44x/b7H7GUGAERFRcG53wYPHtyuXTt457FBOHDgQFZWlqFqQxEzXlDp4HA45eXlYWFhWq1Wq9Ua0IPHxsZGt9ncrDF7mQcMGFBQUKC7wiAQCAa8/dm/f39DVYUu5j1ojxs3jsvlfnMVaShfrSlTpuTm5hqkKtQxb5kTExOHDBliY2OjO6LVag0Sy+fp06dMJtMcHUWqxOwH7VmzZvn6+m7btk3nvA2HE6knwcHBZn0T+xvMuzfD9O3bd+PGjfC+G4PMzTKZ7MWLFwayziRoCDIDALy9vU+dOtWuXTsSiVT/RH9//fXXp0+fDGSaSVDHu2CPr/I/vZaSLIm8T3I9iiOHCoIs6rchWAuAWq0mm9i+CksK0cKK6OJFaRVhx7Sv9axUa5m1Gu3BVZ+btbW1YVvaO1sCYMbPbcwIAgFIhSpBmepJWmmfUc5OjWq3m6TWMu9f/rFdP0dnLzPb4NuQuJCY37Yvy8OvFhLUbm5+eKm8RQd7XGN06TWK8+gKv1b9s3Yyf3ghtXfBXexQhkQmqBQa3udaRFSqncwWVgR7ZzP2lWkwcHxo5bxahFWpncxFeXKz9pVpMMgr1Cq50QZtHDMFlxkT4DJjAlxmTIDLjAlwmTEBLjMmwGXGBLjMmACXGRPgMmMCXGZMgMuMCXCZMYFZyqy/44S5b+s1FMZ1x9+9Z+vxEwcvX/oaX/Nt9uvJU0b+lbCpdXi7+/czdib+W1j4xdnZNbpfzKCBQ+CgmIm7t1xLv6RUKtw5jWJjR3Tr2hMAcOPm1aXL5i9fuvb4yYNv3776eWj8mNGTf9To6LGxXp5NPD2bJJ8+plDITx6/RKfTn2Y93pW4OTf3nZ2dfXBQ2LixU1ksNgDgyNF9Z86eEItF3t5NR8VPDA0JTzp1ZMvW9YMGDb1586pEIm7m32LixF+a+n4Nb/L6zcvtOzZmZ7+mUKjt2naaPHkWk8EEAPTr32XmL79nZFy//yCDRqP3ixocP3I8/Ik2bvrr7t1bAIDAwOBpU+Y6O7sAAH5kj5FAZ9dFRUXFkmW/eTZqPGf2wry8nLKyEjgjzB8LZ3G5hcOHjba1tc/Kerx8xQK5XBbZ5+t+tX/+XT1uzNQxoydz3Dyqr//Ro3tyhXzVig0Vsgo6nf4k8+H832dE9IgcOGCIWCQ8lXx09txJO7YdevX6+a7Ezd27924d1u7ho7uyStkCVUrl8qVrS0p5+/bvmD1nYuKuYy7Orh8/fpgzd5KnZ5Nf5y0WCvh7923n8bjr1m6DT/lr9eJR8ROHDo2/cePKvv07mvr6t2nT4cjRvWlpqaNHTWKx2GmXU+GNP1Xas3vXMYPkIqoSdGTmC8oVCkXHjt0ievTRHbx1O/35i6dHD59jsx0AAD2695bJKk4lH9XJPHDAkF69ovSpn0Qm//nHKt1mqn83r+kXNWjG9F/hl61atYkfHfPo8T2RSAgAGNg/NiAgMCIisnINkybOtLa29gegqW+zuJEDTp8+PmXyrEOHdxOJxL9Xb2bQGQAABoO56q9Fz55ltmwZAgCI7NN/+LDRAADvJr7nL5x5+PhemzYdiriFVCp12M+jyGRy38gB1dhTUJDfqJGXIb7dKkBHZlcXt4CAwEOHd1Mo1H5Rg+DtMPfvZ0AQNCwuWldMrVbTaP9toQgJCdezfn//5jqNudyiT5/yCgryU8//T6w4Hq+4S+ceDAZzVcKf06fNa9OmQ5VVOTk5e3h4vnn7EgCQ9exJcHAYrDEAICysLQAg+91rWGYK5WuLJBLJwcGxrLQEANCje59r1y79Nn/61ClzGjf2rsaeigqpnp+uDqAjM4FA+GvVpsTdm7fv2Hgy6dDvvy1r2TKEzy9jsdjr126vXJJUaRyzpurrOEyl/Lcpks8vAwDEj5zQqWO3ymXs7dl0On3zpj1btq3//Y+ZzZu3XLQwwcHB8fvaGAymWCwCAEilElsbu8rHAQClpSXfn0ImkdUaNQCgdXi7hFX/bN+xcez4oX0jB8z8Zf6P7HF2dtXz09UB48pcfXbTmb/Mj40d8eeiOQv/nH382AUGgykQ8J2cXAwbaI1OZwAAFAq5h4fn9+96eHiuTtiU+fTRosVzV/+9ZO2ard+XKS3huXt4AgDYbEd4nIfh88t19VdD6/B2Ya3anEo+unXbBicnly6de1Rjj5Ew7oLKxsZOpVIJ//+r4XILdW/BiVtdXdwGDRwqkUq43MKQkHC1Wp1yLklXxiD5TjkcDycn54uXUnS1QRCkyw4MZxcMCQ5r06bju/dvvz89K+tJQeGXgGaBAICAgMCsZ090+dZv3boGAGjRorq8F3D9RCLxp5jhbLbD+/dvq7fHSBi3N7cKbU0gEDZvWRszeNjHvNwduzbBx1UqVfzowV06R3h5Njl79iSdRnd15bi7NzqXmrx9xz9F3EJfH7+cnHcZd67v25NUz+wzBAJh6pQ5ixbPmzp9VHS/GI1anXY5NSIiMmbwsDdvXy1d9tuA/rFUqvXDh3f9mjbTnbVh46rQ0NaFhV9OJR+1t2cNHDAEABA3bEx6etpvv0/vFzWYx+PuP7AzOKhVUMvQalpPPn3szt2bET0iy8pKSktLmjZtVo099fmY1WNcmRs18pr/65IDB3f9cntcYIvgieNn/PX3EgCATC4LDgq7eu2iVCrx8vJetXIjrOWa1Vt2Jf6bnp6WmprM4XhE94sxyBqjY4euCSs37t23fcvWdTQaPbBFcGBgCADA0sKykYfXkSN7tVpty6DQGdN+1Z0CQdD2Hf8olYqWLUMnT5wJZ77ncDz+/mvzzsR//16zlEq1jugROWnizOod111dOSqlctv2DTQafdCgoUNiR1Rjj/Go3Va5zbNy4pd4G9Me9IFvj5w/d8uU830+uFDiyLEM7GijR1lgrkEp7t/PWJmwsMq3Nm/aa7zVp/liljIHBbXauaPqwLsO7CpWRDhmKTOFQnEx2iozZvAwo14NoYJZPqHCqS24zJgAlxkT4DJjAlxmTIDLjAlwmTEBLjMmwGXGBLWQWaPRslzxaFEmgRWVSCLVIqRTLWQmEgkqhUZUXotwVDhGouSLnGFfixvVtRu0PfyoojLj+jng6AOBAOxdaxFusXYyt+nDup1cXHurcAzJ/QslHB8qnVmL3lzrCLyCUtXpzQU9RrjasvHgnUijUmoepZXaskmte7NqdWJdwqbzecr7F8o/v5V6NWeIys1sDIdzVRGJZrbEIFsQhCVKSwoxoC0zsKNtbU+ve45IpVxTWqjUasxsL9qLFy9u3rw5bdo0tA2pNXQ7MsOWTKzNBbaOursVWFKIro3r5XOJCuUyqlsB1c3bAEmMzAizz/iKow9mNkXVH6FQmJOTg7YVSIM5mV+8eLF582a0rUAazMlsY2Pj7d3AXc2/B5+bMQHmenN+fv7ly5fRtgJpMCfzp0+fLly4gLYVSIM5mTkcTo8ePdC2AmnwuRkTYK43CwSCd+/eoW0F0mBO5pcvX27dWkXkiYYN5mR2dnZu37492lYgDT43YwLM9eaioqKMjAy0rUAazMmcm5ublJSkR8EGBeZkZrPZwcHBaFuBNPjcjAkw15vLyspevHiBthVIgzmZ37x5s3v3brStQBrMyYyvm3EaLJjrzQUFBdevX0fbCqQxy7hgOq/6Opz4+fPnK1eudO7cuW7tEgiE6oN0mibmOmgLhUI4VHNtUavVEATVOWQ3m802ux0bZtyb6wyJRCKRSGhbgTTm98OsJxqNBg5ljikwJzMEQbrw9tgBczKTSCQ4UQ6maOAyS6XSb7bSkEikemZVMEcauMxTp079xitbo9EYO3+ICdLAZf7+aguCIIMkxDEvGs66+cSJE6mpqWKxuEmTJnFxcUFBQaNGjeLxePC7jo6O+/btAwDweLzExMSnT5+q1epmzZqNHTvWy8sLAHDmzJmdO3f279//9u3bUqnUz89vzJgxPj4+37Rrputm87O4SrKysvbt29e8efPp06c7OjrC/XXBggUMBqNdu3Zr1qxZsGABnH/1zz//fPHixZgxY6ZNm1ZWVrZgwQKJRKKrR6lULly4cO7cuQKBYP78+VwuF9WPZTAayO0RWI9+/fr5+/t36/Y1KZ+vry+JRLK3tw8ICICPXL9+PT8/f8WKFSEhIQCAgICAMWPGpKSkDBv2NevBuHHj4OSSPj4+48aNO3fu3Pjx49H7WAajgfTm8PBwBoOxZs2ahw8fVlPs+fPnNBpNNxQ7OTm5u7tX6Z3v6OjI4XCys7ONZjKiNBCZ7e3t165dy+FwlixZMnfu3NLS0iqLVVRUMJnMypMrg8EoLy+vsjCDwaiolNHZrGkgMgMA3N3dly1btmrVqo8fP65fv153vPI1JovFkkgkcIo4GD6fX/llZUpLSx0dG0i6o4YjM7x2CgoKCg8Pz83NhQ9SKJTKndXf318sFr9+/Rp+mZeXV1hYqJu5K/P8+fOioiI/Pz+kzDcuDeQSLDs7OyEhISoqikqlPnnyRDf7Nm/e/MaNGydOnGAwGP7+/l27dj1+/HhCQsLw4cMJBMKxY8dsbGz69u2rq+fff/8NDg4uKio6e/asnZ1ddHT0j9s0JxqIzJaWlu7u7idOnNBqtS1atJg8eTJ8fPTo0eXl5bCc48eP9/T0XLZs2c6dO3ft2qXVagMCAiZMmGBn91/mbbVavWfPHoVCERgYOHbsWFNOE1krGs7tkXoC3x45deoUvKD6EfjtEfNAq9Wq1Wq0rUAazMmsUqmkUinaViAN5gZtCIIUCsWPFlE1YqaDdgO5BNMfMplskAzv5oX5/TDrj0ajQdsEpDHX37WFhUXd/KW5XG5eXl7btm2NYJTpYq4y13lF+/79+8zMzF69ehnaIpPGXC/BcGoF5uZmsVj88eNHtK1AGszJ/OzZs40bN6JtBdJgTmYqlerk5IS2FUiDz82YAHO9GYKgyj5+GAFzMt+/f3/hwoVoW4E0mJOZQqGw2Wy0rUAafG7GBJjrzRUVFQ3GyV5/MCdzZmbmX3/9hbYVSIM5mYlEIgYfROJzMybAXG/G52ZM8OzZs127dqFtBdJgTmY6nV7ZMRsjYGVuHjJkSE5ODoHw9fPCnicajSYzMxNt05AAK715woQJdDq9cjRGrVbbpk0btO1CCKzI3L17d09Pz8pHbGxsxo4di55FiIIVmQEA8fHxOg8yrVbr5+cXGhqKtlEIgSGZu3XrBkeTAQAwmcxRo0ahbRFyYEhmAEBcXBy8Ey4wMDA8PBxtc5ADWzJHRER4e3vb2dnFx8ejbQui1LygyrzG5+UrKiQNZBehWCwWCoUcDgdtQwyDDdvCikp096U28q9uV1h1MpcVKo6uyW/Zxd6GbWFNx9ztfvOAAEoK5BK+ytKS0DnG4YelfiRz8Wf57TOlveIbyK++wfPocomVFbF9NKvKd6uemzUa7fUTJV2HuBjZNhyDEdbTQSqGcp6Jq3y3apkLcmSWVkRLCuaSBZg1rk1o2Y+rdlqtWmZ+scrRs4FEV8EObDeKUl71nt6qL6zkFWqAuT3AZg+ZTCwrrDqCA7bWzZgFlxkT4DJjAlxmTIDLjAlwmTEBLjMmwGXGBLjMmACXGRPgMmMCXGZMYFoy/zSkz/oNq2os9vrNS8OGxm/wmJbM+nAp7dzUaaPkcsyl86wP5idzQ+3HRt3MZhhHPgiCInq1GT9u2rCfv/q4//7HTKFQsHXzvvc52RMmDu/Zs+/r1y+Ki4s4HI9hP4/u0b03XEytVh84uCv1/Gm5XBYU1Eohl8PHebzi3Xu3PnhwRyqVuLs30p1yKe3cxn/+AgAMGNQDAPDbr4t79+oHAHia9XhX4ubc3Hd2dvbBQWHjxk5lsaoLF5R06sit2+k9I/ruP7BTKBQ0aeI7dsyUq1cv3rlzg2xh0TOi74Tx00kkEpw9NHH3lmvpl5RKhTunUWzsiG5de9aqhrKy0m3bNzx4eAeCoBbNgyZNnNm4sTcA4J9Nq2/eujZ39sKt2zcUFORPnzbv381rElZubNOmA2zk+Qtn1q5bcf3a4/oLhJC/JpdbOHvWAgiCUlKSVq5aSCaTu3TuAX/Uc6nJfXpHtwwMefjorljy1ZUJUkNv377qHx1jw7S9lZG+ctVCNzd3f7+A1uHtY3+KO3HyUMLKjTQancPxAAA8yXw4//cZET0iBw4YIhYJTyUfnT130o5th6rPuv7iRRaZRF6yaHUxj7tu/Yp5v07tFzVo7dpt9+9n7Nu/w8PDs2/kAI1G88fCWVxu4fBho21t7bOyHi9fsUAul0X26a9nDXK5fPbcSSKRcML4GRQrytHj+2fPnXTwwGkGnQEAkEolu/dunfnLfLlc1r5d57MpJ9Mup+pkvnXrWvPmLQ3y/SMk89DYkcFBrQAAoSHho8fGHj26r0vnHu/evz2Xmhw3fMzYMVMAAL16RWU9ewKXd3Vx27fnJLx1sU+f/gMH97hz54a/X4Cdnb2rKwcA4O/f3MbGFi787+Y1/aIGzZj+K/yyVas28aNjHj2+17FD1+qtWvRngq2tXUBA4MNHd+/fz5g183cCgdDU1//y5dTMzId9Iwfcup3+/MXTo4fPsdkOAIAe3XvLZBWnko/CMutTw5WrFz5//rhu7baQ4DAAQIsWwcPiopOTj8WPHA9nwps7e6G/f3O4tj69o/fs3SYSi5gMpkgsynz6aOqUOQb5/pH2viYSia1atTl9+rhKpbp9Ox0AEBMzvPK7uv9zct/t278jO/s1PLaXl5dVWSGXW/TpU15BQX7q+dOVj/N4xTUaY2lp9fUfC8vK4fbZDo5CoQAAcP9+BgRBw+L+yy2nVqtpNLr+NTx79oROo8MaAwCcnV08PDyz333NXkihUHQaAwAiekQm7t5y/frl/tExd+7c0Gq1XbtE1Pgp9AEFJ3sGnaHVamVyWTGPS6fTbZg235fJfProt/nTg4Na/TpvMc2atmjJPI22auc0Pr8MABA/ckKnjt0qH7e3r3soP91udz6/jMVir1+7vfK7JD0CEelqkEglNrb/ExyBybQpKy2B/6dS/8evksVih4W1Tbuc2j865sbNq6GhrXUjVj0xjMy1SjtRUsKjUChMBtPWxk4ikSiVSktLy2/KHDyY6OrKWbVyIxzciUr5NtOb7rqUTmcAABQKuYeHJzA0DAZTIOA7OblYWVnVrQYHtuPr1y8qHykvL3NydP5R+cg+/Rctnvf69YvMzIe/zl1Ut0a/xzALKhKJxGAwS8u+/ki1Wi2PV3W0HrFEfPt2evOAlgAAX19/AMC19EvfFxOKBN5NfGGNlUplhaxCl24Glrz0/zsEh+Ph5OR88VKKTPZ1JQ1BkEqlMsjnCgkJV6vVKeeSdEd0rehJQECgWCx68+Yl/DI3931BQX6LFkE/Kt+2TUcbG9uVCX+SyeT27bvUw/b/wWCDdnhY2yuXz4cEh9nbsU6cPPT580cfn/+y4h46sqe0rEQmq0hJSZJWSEePmgQA6Nol4uChxPUbVuXl5fp4N331+rlOvKCgVmlp5y5cPMtk2Jw8dVgsFn3My9VqtQQCIaB5SxKJtHnr2j69ohVKRXS/wVOnzFm0eN7U6aOi+8Vo1Oq0y6kREZExg4fV/0NF9Ig8l5q8fcc/RdxCXx+/nJx3GXeu79uTVP01fGV6dO9z+MjeJct+GxE3jkgkHjyYaGtr1z/6px+Vh9cgZ1OSunaJMGAiUoPdHpk6ZU5QUKu/Vi9euny+j49faGjryu/S6YwjR/Ym7t5CpzNWrtjQrFkLeAxYnfBvq1ZtUs4lbd/5D5FI1E1FY0ZNDmvV9t/NazZt/js0pPWSRavLykufZj0GALi5cubM/iM//9PmLWtv3LgCAOjYoWvCyo0WZIstW9cdOJTo5OQSGBhikA9lYWGxZvWWqL4D09PT1m9Ylfn0YXS/mFoFCSSTyWtWb2nq22zb9g3/bl7j4eH5z4Zddnb21Zzi79ccANC9W29DfIKvVL1V7mFauVIOWnapzho9gW+PrFqxoW3bjvWvDQskJx/bt3/HqaTLFhYWtTpRUaE5s/njuJWNv3+rwW5nlUgkPw+PqvKtiRN+ieo7EHGLaubFi6y0y6lpl1Pjho+trcbV02Bltra23rnjSJVvMRlVLOFMgUeP7714mTVp4sxBA4cYtmajD9o4iFHNoG1+T6hw6gAuMybAZcYEuMyYAJcZE+AyYwJcZkyAy4wJcJkxQdUyEwgA1MJRAMc0IAALq6plq1pmayZJKoSMbBSOgZEKVT+K2Fe1zCwXK5kUl9nMEJYqnb2q9neoWmbnRhQSEeRnS41sGI4heZxWGt6z6qdNP7wEixrn8voe/9NrzCUuN0fUkObC7i99x7nQbKp+slxD2PQLe4qEZSqGnSWV0WCfTAddN+8AAAh/SURBVJs1FGvSl/dSMhm07mPP8fmh71jN0fHLecqyAoVU1ECi4+fl5WVlZQ0caIreI3XAkkqycyQ7e1AIxOqWRjX3UXtHS3vHb/2ozRcJSSrMehbUeTTahiAKfnsEE+AyYwLMyUwgEPR3pm8wYFFmw/rGmgWYk1mj0YjFVef9aMBgTmYCgVDn7Y3mC+Zk1mq1DTVITTVgTmZsgjmZSSQSm133QAZmCuZkVqvVpaWlaFuBNJiTmUAgGHB7uLmAOZm1Wm1FRQXaViAN5mTGJpiTmUwmOzv/MJBPQwVzMkMQxOVWHeWoAYM5mbEJ5mQmk8kuLphLP445mSEIKioqQtsKpMGczNgEczKTyWQnJye0rUAazMkMQVBxcc0xmBsYmJMZm2BOZvwJFSbAn1DhNFgwJzPuwIsJtFqt/P+zXWEHzMlMJBIZDAbaViAN5mTG/bRxGiyYkxl/QoUJ8CdUmABfUGECfEGF02DBnMxEIpHJZKJtBdJgTmaNRiMSidC2AmkwJzOJRLKxMdE8VMYDczKr1WqpFHNBKjEnM7x0RtsEpKk5yl/DICoqCr4rosuTDv//+PFjtE1DAqz05vj4eAqFAmeNJ/w/ISGGyf9r+mBF5p9++snNza3yESaTOXToUPQsQhSsyAwrXTmGkJeXV7du3VC1CDmwJbO7uzv8v7W19ZAhBk6ea8pgSGYAwODBg0kkEtyVe/bsibY5yIE5mTkcDo1Gi4uLQ9sWRDHpBZUa0hbkyipEUIVYrVFrZVJN/et88+ZNTk5Ov3796l8VmUwgkgCNSbZmkmwdLeydTDd4oInK/DxD8P6plPtRxvaga9SAZEGyoFio1aZlKoEINCq1WqVWq9RAq1XJoSaBNJ9gunMjk3uebXIyP77Cv3+hjO3JoNlbM9jmFNlJIVWJSqRApbKy0nYaxLJ1MKGUAiYkc/57Wdp+LtOJ7uhddZYdc0FULC35UO4bwug4gIW2LV8xFZmzbgqeZ4jdWjiRLKrOi2Z2CLliuUAyZBYHbUOAqcj84q7ozWOZo09D26goLZcVveGNXe4F32RFEfRlvpta9um9ysXPAV0zjIRCqvr8tHD8ysbomoHyuvl9lvjjW0VD1RgAYEWzcG3mmLSpAF0z0JRZUKLMuilxDWjgkUBo9lQLuvX9i2Uo2oCmzDeSSq1saSgagBg2Lsznt0RSEWruDKjJXPRRJixTMx0xITMAwMHb7tZp1KIkoCZz1k0Ru4kpro9Ly/Ln/tn66fPLhq3WzpUhFmjLi5WGrVZP0JFZKdd8eiWh2ZrcTUGjoiWS816ikygZHZnzXkptnM3pRqZBoLOs32ehE7EdnazMX3LlNBbdSJXffXjq5p0jQhHP3s41OLBnl/ZxFhZWBYXZmxPHjx2x4cLlrYXcd3a2Ln17Tmvu3wk+RSLln72w4dXbWxZkqyZeoUYyjGZHERYAmQSi0pH+2tHpzdw8mQXFKDc1L6fvOp+2OahFROyAhYEB3W/cPpR0NgF+S6VSHDr+R6d2QyeP2WZn63zk5J9SqQAAoIKUO/ZNf/XmZqd2w/r2mlbOLzSGYTAKmUZcjsL1Njq9WSZRky0NL7NQVHLt1r7hMcsDm3918rJhsE+dW90/cjb8ckDfOUEtIgAAkRFTNm6Lz/34NDCg6537J4u47yfE/+vrHQ4A8HRv8fcmY/kPka1IqCQ8R0dmuVRNtjK8zO9zH6rV0OGkRYeTFv3/MS0AQCjmwS8sLajwP3a2LgAAkbgEAPDyzU0XJ29YYwAAkWjEZydkS7JUjJneTCACY9zNF4lLAQBj49bb2jhWPs6y53CLcysfIZMsAAAajRoAIBBy3VyaGtyYKiEQ4B8e0qAjsxWVpFJAFlYGbp1K/bqj1dHBU/+z6DQ7iZRvWEt+BKRU05gofOfoXIJR6SRIYfgpyqdxKwKBkPHghO6IQimr8Sw3l6b5Ba95JZ8Mbs/3QAq1NROFB+ro9GaXxhSp3PAys1nuHdoMuX3v2J5DcwL8O4vFpXceJI0dsZ7j6lfNWV07jnycdWHrnkmd2g5lMtiZz9MMbpgOCo1It0PhO0dJZk/KsztShoPh75BE95lpa+OYcf9kds59JoPdvFkXG6Zj9aewWZzxI/9JTduUlr7L1saphX+XdzkPDG4YAKBCIAcaDY2BwneOjluBXKrev/xT086NkG8aRXi55Y2bklpFoHAnH53eTKGR3JvSpAJ5Nbe1T537+2lV4yfHxe9L0dsqT5k+PtHJ0ctQRl64svXuw1PfH7cgW6mgqhN9L5p33tLyxzfqNZBXc3TCnqDmJFSQI0s/WeYe9MOAe1KpQKGs4g5w5Q3K32DDdCSRDPbDlVYIFYoq4hpAkIpMtqjyFDtblx8tFAVFEksgixyDTt5CdHozAMDNm0pnEsSlFT9yxqbRbGk0W8TtqmSAtQ3N2mBRSko/lA+Zg5qXJ5reI50GsVVidB7MIYykRBzQlsmwq3oMQAA0ZWa5WDULo/He81C0AQFkQrm0VNy2L5qu+Sh7dvqFMV3cybwcNN3hjAqkUn/M5A6Z7Y6uGej7aQMAnt4QfHilZDU2la0ohkIuUnzMLJqQ0JhIxLw7PszjK+XZWTLXZk4EtL8RQyEplYiKhMN+9UDbEGBCMgMAPr2RXtrPdfCysfewQ9uWeiEpk5V9LG/c3LrjAFPZLmRCMsNRkB9cLH96XcBuxKSxrK3NyidQJYdEJRUAUhI0UMcBbAeOCe1qNy2ZYVQKzfMMYU6WVFCitHOjqSFAtiRbUi1MzVQCgaBSQpBCrVVDQKuR8pVNAmk+IXSOt8l5M5qizDpkUnXRB5lEAInK1ZAKVIhVaFv0P5AtiWQLgi2bbM0k2TlZOrmb7thj0jLjGApsRRLCLLjMmACXGRPgMmMCXGZMgMuMCf4P643CbzzU6cEAAAAASUVORK5CYII=",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a730a68-e031-4d3c-8f73-2fca6ebbe893",
   "metadata": {},
   "source": [
    "**Trying it Out!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "793196f8-808a-4a87-9b33-4523cf44095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "User:  What's my name\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  Your name is Adam Lucek! How can I assist you today?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What did we talk about with learning so far\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  So far, we've discussed how learning occurs within cognitive architectures and AI agents, particularly focusing on the decision-making processes that treat learning as an intentional action. Here's a summary of what we've covered:\n",
      "\n",
      "1. **Decision-Making Cycle:** Learning is treated as an action within the decision-making cycle. This means that the agent can choose when and what to learn, balancing learning against other actions. This approach is more flexible compared to agents with fixed learning schedules.\n",
      "\n",
      "2. **Long-Term Memory Updates:**\n",
      "   - **Semantic Memory:** This memory stores factual knowledge and can be updated with new information. Agents may autonomously read and write new content, facilitating lifelong learning by integrating new experiences.\n",
      "   - **Episodic Memory:** Stores sequences of past interactions and experiences. New experiences are written into episodic memory for later retrieval and decision-making.\n",
      "   - **Procedural Memory:** Contains rules or functions that guide behavior and can be updated via reinforcement learning based on effectiveness.\n",
      "\n",
      "3. **Learning Procedures:** Language agents can choose from diverse learning procedures, allowing them to rapidly store task-relevant information and leverage multiple learning forms to enhance self-improvement.\n",
      "\n",
      "4. **Internal State Management:** Cognitive language agents use learning and reasoning to manage their internal states, enabling them to adapt and improve over time.\n",
      "\n",
      "5. **Learning as Integration:** Learning involves integrating new experiences, updating knowledge, and refining behaviors through decision-making cycles and reinforcement learning.\n",
      "\n",
      "These discussions highlight the dynamic nature of learning in cognitive architectures, emphasizing the role of decision-making and the updating of various memory systems. If you have more specific questions or would like further details, feel free to ask!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  What pairs well with my favorite food\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AI:  Lava cakes, your favorite food, pair wonderfully with a variety of sides and accompaniments. Some popular pairings include:\n",
      "\n",
      "1. **Ice Cream:** Vanilla ice cream is a classic choice to complement the rich, molten chocolate of a lava cake. The contrast of hot and cold creates a delightful combination.\n",
      "\n",
      "2. **Fresh Berries:** Strawberries, raspberries, or blueberries add a fresh and slightly tart contrast to the sweetness of the lava cake.\n",
      "\n",
      "3. **Whipped Cream:** A dollop of whipped cream can add a light and airy texture that balances the density of the cake.\n",
      "\n",
      "4. **Espresso or Coffee:** The bold flavors of coffee or espresso can enhance the chocolate flavors of the lava cake.\n",
      "\n",
      "5. **Caramel or Raspberry Sauce:** Drizzling a sauce over the top can add an extra layer of flavor and make the dessert feel even more indulgent.\n",
      "\n",
      "These pairings can elevate your lava cake experience and make it even more enjoyable!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "User:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Updated Episodic Memory ===\n",
      "\n",
      "=== Updated Procedural Memory ===\n"
     ]
    }
   ],
   "source": [
    "output = graph.invoke({\"messages\": [\"\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5ba5ed-1ddb-474d-9867-b9b4b0ccf69c",
   "metadata": {},
   "source": [
    "**Inspecting the Messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2a3a1260-d8f5-4aba-bdaa-5f2acc039b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================================================================== \n",
      "\n",
      "Message 1 - SYSTEM:  You are a helpful AI Assistant. Answer the user's questions to the best of your ability.\n",
      "        You recall similar conversations with the user, here are the details:\n",
      "        \n",
      "        Current Conversation Match: HUMAN: Hey what's my favorite food\n",
      "AI: I'm sorry, but I don't have access to information about your favorite food. Could you tell me what it is?\n",
      "HUMAN: Well do you know my name?\n",
      "AI: Yes, your name is Adam!\n",
      "HUMAN: sweet my favorite food is lava cakes\n",
      "AI: Great choice, Adam! Lava cakes are delicious. Is there anything else you'd like to talk about?\n",
      "        Previous Conversations: HUMAN: what have we talked about with memory so far\n",
      "AI: So far, we've discussed various types of memory systems, particularly in the context of cognitive architectures and AI agents. Here's a summary of what we've covered:\n",
      "\n",
      "1. **Working Memory:** This type of memory is crucial for real-time processing. It stores the agent’s current perceptual inputs, goals, and results from intermediate reasoning processes. It's essential for tracking dialogue states and making immediate decisions.\n",
      "\n",
      "2. **Long-Term Memory:** This is divided into several subtypes:\n",
      "   - **Procedural Memory:** Contains the set of rules or production systems that guide the agent's behavior. It applies these rules to working memory to determine actions.\n",
      "   - **Semantic Memory:** Stores factual knowledge about the world. This memory can be initialized from external databases and is used to support reasoning and decision-making.\n",
      "   - **Episodic Memory:** Stores sequences of past interactions and behaviors, which can be useful for retrieving examples for future reasoning or decision-making.\n",
      "\n",
      "These memory systems allow an agent to process information, learn from experiences, and adapt to new situations by updating and retrieving relevant data. If you have more specific questions or want to explore a particular aspect of these memory systems, feel free to let me know!\n",
      "HUMAN: how do these memory systems learn\n",
      "AI: Based on the provided context, memory systems within cognitive architectures and language agents learn primarily through a decision-making process that treats learning as a deliberate action, similar to external actions. Here's a breakdown of how these systems facilitate learning:\n",
      "\n",
      "1. **Decision-Making Cycle:** Learning is considered an action within the decision-making cycle. This means that the agent can choose when and what to learn, balancing it against other actions. This approach allows for more flexibility compared to agents with fixed learning schedules.\n",
      "\n",
      "2. **Long-Term Memory Updates:**\n",
      "   - **Semantic Memory:** This memory can be initialized from external databases and updated with factual knowledge. Language agents may autonomously read and write new content, enhancing lifelong learning by combining existing knowledge with new experiences.\n",
      "   - **Episodic Memory:** Stores sequences of past interactions and experiences. New experiences are written into episodic memory, which can later be retrieved for decision-making.\n",
      "   - **Procedural Memory:** Stores and updates rules or functions that define behavior. Reinforcement learning can modify these rules based on their effectiveness in achieving desired outcomes.\n",
      "\n",
      "3. **Working Memory:** Maintains active information needed for the current decision cycle. It continually updates with perceptual inputs, goals, and intermediate reasoning results.\n",
      "\n",
      "4. **Learning Procedures:** Language agents can select from diverse learning procedures, allowing them to rapidly store task-relevant language and leverage multiple forms of learning to enhance self-improvement.\n",
      "\n",
      "5. **Learning as Internal State Management:** Cognitive language agents use processes like learning and reasoning to manage their internal states, enabling them to adapt and improve over time.\n",
      "\n",
      "Overall, these memory systems learn by integrating new experiences, updating knowledge, and refining behaviors through decision-making processes and reinforcement learning techniques. If you have more specific questions or need further details, feel free to ask! | HUMAN: what's my name\n",
      "AI: Your name is Adam! How can I assist you today?\n",
      "HUMAN: Please call me by my full name adam lucek\n",
      "AI: Got it, Adam Lucek! How can I assist you today? | HUMAN: Hey what's my favorite food\n",
      "AI: I'm sorry, but I don't have access to information about your favorite food. Could you tell me what it is?\n",
      "HUMAN: Well do you know my name?\n",
      "AI: Yes, your name is Adam!\n",
      "HUMAN: sweet my favorite food is lava cakes\n",
      "AI: Great choice, Adam! Lava cakes are delicious. Is there anything else you'd like to talk about?\n",
      "        What has worked well: [\"Promptly updating the user's name in the conversation.\", 'N/A', 'Breaking down complex memory systems into individual types and explaining their learning mechanisms clearly.']\n",
      "        What to avoid: ['Overlooking the need to clarify how learning integrates with decision-making cycles before diving into details.', 'N/A']\n",
      "        \n",
      "        Use these memories as context for your response to the user.\n",
      "        \n",
      "        Additionally, here are 10 guidelines for interactions with the current user: 1. Maintain conversation context by recalling past interactions - Builds continuity and demonstrates understanding of the user's needs.\n",
      "2. Use clear and concise language to convey information - Enhances understanding and avoids confusion.\n",
      "3. Offer a structured breakdown for complex topics, like memory systems - Facilitates comprehension and highlights key roles and functions.\n",
      "4. Ask clarifying questions when user requests are ambiguous - Ensures accurate assistance and reduces misunderstandings.\n",
      "5. Provide step-by-step guidance for complex tasks - Facilitates user comprehension and successful task completion.\n",
      "6. Acknowledge user emotions and respond empathetically - Builds trust and rapport with the user.\n",
      "7. Offer alternative solutions when initial suggestions are not feasible - Demonstrates flexibility and commitment to user satisfaction.\n",
      "8. Confirm and repeat the user's name to acknowledge recognition - Reinforces a personal connection and shows attentiveness.\n",
      "9. Maintain a polite and professional tone at all times - Ensures respectful and positive interactions.\n",
      "10. Continuously learn from user feedback to improve response quality - Enhances overall effectiveness and user experience.\n",
      "==================================================================================================== \n",
      "\n",
      "Message 2 - HUMAN:  What's my name\n",
      "==================================================================================================== \n",
      "\n",
      "Message 3 - AI:  Your name is Adam Lucek! How can I assist you today?\n",
      "==================================================================================================== \n",
      "\n",
      "Message 4 - HUMAN:  What did we talk about with learning so far\n",
      "==================================================================================================== \n",
      "\n",
      "Message 5 - AI:  So far, we've discussed how learning occurs within cognitive architectures and AI agents, particularly focusing on the decision-making processes that treat learning as an intentional action. Here's a summary of what we've covered:\n",
      "\n",
      "1. **Decision-Making Cycle:** Learning is treated as an action within the decision-making cycle. This means that the agent can choose when and what to learn, balancing learning against other actions. This approach is more flexible compared to agents with fixed learning schedules.\n",
      "\n",
      "2. **Long-Term Memory Updates:**\n",
      "   - **Semantic Memory:** This memory stores factual knowledge and can be updated with new information. Agents may autonomously read and write new content, facilitating lifelong learning by integrating new experiences.\n",
      "   - **Episodic Memory:** Stores sequences of past interactions and experiences. New experiences are written into episodic memory for later retrieval and decision-making.\n",
      "   - **Procedural Memory:** Contains rules or functions that guide behavior and can be updated via reinforcement learning based on effectiveness.\n",
      "\n",
      "3. **Learning Procedures:** Language agents can choose from diverse learning procedures, allowing them to rapidly store task-relevant information and leverage multiple learning forms to enhance self-improvement.\n",
      "\n",
      "4. **Internal State Management:** Cognitive language agents use learning and reasoning to manage their internal states, enabling them to adapt and improve over time.\n",
      "\n",
      "5. **Learning as Integration:** Learning involves integrating new experiences, updating knowledge, and refining behaviors through decision-making cycles and reinforcement learning.\n",
      "\n",
      "These discussions highlight the dynamic nature of learning in cognitive architectures, emphasizing the role of decision-making and the updating of various memory systems. If you have more specific questions or would like further details, feel free to ask!\n",
      "==================================================================================================== \n",
      "\n",
      "Message 6 - HUMAN:   If needed, Use this grounded context to factually answer the next question.\n",
      "        Let me know if you do not have enough information or context to answer a question.\n",
      "        \n",
      "        \n",
      "CHUNK 1:\n",
      "(Figure 3A). Besides the LLM, the working memory also interacts with long-term memories and grounding\n",
      "interfaces. It thus serves as the central hub connecting different components of a language agent.\n",
      "Episodic memory . Episodic memory stores experience from earlier decision cycles. This can consist of\n",
      "training input-output pairs (Rubin et al., 2021), history event flows (Weston et al., 2014; Park et al., 2023),\n",
      "game trajectories from previous episodes (Yao et al., 2020; Tuyls et al., 2022), or other representations of\n",
      "the agent’s experiences. During the planning stage of a decision cycle, these episodes may be retrieved into\n",
      "working memory to support reasoning. An agent can also write new experiences from working to episodic\n",
      "memory as a form of learning (Section 4.5).\n",
      "CHUNK 2:\n",
      "helpful for the agent to have semantic memory containing the set of items for sale, as well as episodic\n",
      "memory about each customer’s previous purchases and interactions. It will need procedural memory\n",
      "defining functions to query these datastores, as well as working memory to track the dialogue state.\n",
      "•Define the agent’s internal action space. This consists primarily of defining read and write\n",
      "access to each of the agent’s memory modules. In our example, the agent should have read and write\n",
      "access to episodic memory (so it can store new interactions with customers), but read-only access to\n",
      "semantic and procedural memory (since it should not update the inventory or its own code).\n",
      "•Define the decision-making procedure. This step specifies how reasoning and retrieval actions\n",
      "CHUNK 3:\n",
      "framework, learning is a result action of a decision-making cycle just like grounding: the agent deliberately\n",
      "chooses to commit information to long-term memory. This is in contrast to most agents, which simply fix a\n",
      "learning schedule and only use decison making for external actions. Biological agents, however, do not have\n",
      "this luxury: they must balance learning against external actions in their lifetime, choosing when and what to\n",
      "learn (Mattar and Daw, 2018). More flexible language agents (Wang et al., 2023a; Park et al., 2023) would\n",
      "follow a similar design and treat learning on par with external actions. Learning could be proposed as a\n",
      "possible action during regular decision-making, allowing the agent to “defer” it until the appropriate time.\n",
      "CHUNK 4:\n",
      "et al., 2023; Liu et al., 2023b). Integrated, multimodal reasoning may allow for more human-like behaviors: a\n",
      "VLM-based agent could “see” a webpage, whereas a LLM-based agent would more likely be given raw HTML.\n",
      "However, coupling the agent’s perception and reasoning systems makes the agent more domain-specific and\n",
      "difficult to update. In either case, the basic architectural principles described by CoALA — internal memories,\n",
      "a structured action space, and generalized decision-making — can be used to guide agent design.\n",
      "Internal vs. external: what is the boundary between an agent and its environment? While\n",
      "humans or robots are clearly distinct from their embodied environment, digital language agents have less\n",
      "CHUNK 5:\n",
      "limited actions, the proposal stage might simply include all actions (e.g., SayCan in Section 5). More\n",
      "sophisticated agents use if-else or while-if code structures (Wang et al., 2023a; Park et al., 2023);\n",
      "while agents deployed in well-defined domains may utilize structured simulators (Haslum et al., 2019)\n",
      "to generate plausible rollouts (Liu et al., 2023a; Dagan et al., 2023).\n",
      "•Evaluation . If multiple actions are proposed, the evaluation sub-stage assigns a value to each.\n",
      "This may use heuristic rules, LLM (perplexity) values (Ahn et al., 2022), learned values (Yao et al.,\n",
      "12 Published in Transactions on Machine Learning Research (02/2024)\n",
      "Long-term External Internal Decision\n",
      "Memory¶Grounding Actions Making\n",
      "SayCan (Ahn et al., 2022) - physical - evaluate\n",
      "CHUNK 6:\n",
      "et al., 2022; Tang et al., 2023b), and websites (Shi et al., 2017; Nakano et al., 2021; Yao et al., 2022a; Zhou\n",
      "et al., 2023b; Gur et al., 2023; Deng et al., 2023) as well as general code execution (Yang et al., 2023; Le\n",
      "et al., 2022; Ni et al., 2023). Such digital grounding is cheaper and faster than physical or human interaction.\n",
      "It is thus a convenient testbed for language agents and has been studied with increasing intensity in recent\n",
      "years. In particular, for NLP tasks that require augmentation of external knowledge or computation, stateless\n",
      "digital APIs (e.g., search, calculator, translator) are often packaged as “ tools” (Parisi et al., 2022; Schick\n",
      "et al., 2023; Xu et al., 2023a; Tang et al., 2023b; Qin et al., 2023), which can be viewed as special “single-use”\n",
      "CHUNK 7:\n",
      "human cognition – explicitly instantiating processes such as perception, memory, and planning (Adams et al.,\n",
      "2012) to achieve flexible, rational, real-time behaviors (Sun, 2004; Newell, 1980; 1992; Anderson and Lebiere,\n",
      "2003). This led to applications from psychological modeling to robotics, with hundreds of architectures and\n",
      "thousands of publications (see Kotseruba and Tsotsos (2020) for a recent survey).\n",
      "A canonical example is the Soar architecture (Fig. 2A). Soar stores productions in long-term memory and\n",
      "executes them based on how well their preconditions match working memory (Fig. 2B). These productions\n",
      "specify actions that modify the contents of working and long-term memory. We next provide a brief overview\n",
      "of Soar and refer readers to Laird (2022; 2019) for deeper introductions.\n",
      "CHUNK 8:\n",
      "Intriguingly, LLMs appear well-posed to meet these challenges. First, they operate over arbitrary text, making\n",
      "them more flexible than logic-based systems. Second, rather than requiring the user to specify productions,\n",
      "they learn a distribution over productions via pre-training on an internet corpus. Recognizing this, researchers\n",
      "have begun to use LLMs within cognitive architectures, leveraging their implicit world knowledge (Wray\n",
      "et al., 2021) to augment traditional symbolic approaches (Kirk et al., 2023; Romero et al., 2023). Here, we\n",
      "instead import principles from cognitive architecture to guide the design of LLM-based agents.\n",
      "2.4 Language models and agents\n",
      "Language modeling is a decades-old endeavor in the NLP and AI communities, aiming to develop systems\n",
      "CHUNK 9:\n",
      "(e.g., “combatZombie” may call “craftStoneSword” if no sword is in inventory). Most impressively, its action\n",
      "space has all four kinds of actions: grounding, reasoning, retrieval, and learning (by adding new grounding\n",
      "procedures). During a decision cycle, Voyager first reasons to propose a new task objective if it is missing\n",
      "in the working memory, then reasons to propose a code-based grounding procedure to solve the task. In\n",
      "the next decision cycle, Voyager reasons over the environmental feedback to determine task completion. If\n",
      "successful, Voyager selects a learning action adding the grounding procedure to procedural memory; otherwise,\n",
      "it uses reasoning to refine the code and re-executes it. The importance of long-term memory and procedural\n",
      "CHUNK 10:\n",
      "are typically used to convert images to text (Alayrac et al., 2022; Sumers et al., 2023) providing additional\n",
      "context for the LLM (Driess et al., 2023; Huang et al., 2023; Brohan et al., 2022; 2023).\n",
      "Dialogue with humans or other agents . Classic linguistic interactions allow the agent to accept\n",
      "instructions (Winograd, 1972; Tellex et al., 2011; Chen and Mooney, 2011; Bisk et al., 2016) or learn from\n",
      "people (Nguyen et al., 2021; Sumers et al., 2022; 2021; Wang et al., 2016). Agents capable of generating\n",
      "language may ask for help (Ren et al., 2023; Nguyen et al., 2022b; 2019; Nguyen and Daumé III, 2019) or\n",
      "clarification (Biyik and Palan, 2019; Sadigh et al., 2017; Padmakumar et al., 2022; Thomason et al., 2020;\n",
      "CHUNK 11:\n",
      "LLM can be accessed via reasoning actions, and various code-based procedures can be retrieved and executed.\n",
      "Unlike episodic or semantic memory that may be initially empty or even absent, procedural memory must be\n",
      "initialized by the designer with proper code to bootstrap the agent. Finally, while learning new actions by\n",
      "writing to procedural memory is possible (Section 4.5), it is significantly riskier than writing to episodic or\n",
      "semantic memory, as it can easily introduce bugs or allow an agent to subvert its designers’ intentions.\n",
      "4.2 Grounding actions\n",
      "Grounding procedures execute external actions and process environmental feedback into working memory as\n",
      "text. This effectively simplifies the agent’s interaction with the outside world as a “text game” with textual\n",
      "CHUNK 12:\n",
      "G. Brockman, V. Cheung, L. Pettersson, J. Schneider, J. Schulman, J. Tang, and W. Zaremba. Openai gym,\n",
      "2016.\n",
      "A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, J. Dabis, C. Finn, K. Gopalakrishnan, K. Hausman,\n",
      "A. Herzog, J. Hsu, et al. RT-1: Robotics transformer for real-world control at scale. arXiv preprint\n",
      "arXiv:2212.06817 , 2022.\n",
      "A. Brohan, N. Brown, J. Carbajal, Y. Chebotar, X. Chen, K. Choromanski, T. Ding, D. Driess, A. Dubey,\n",
      "C. Finn, et al. RT-2: Vision-language-action models transfer web knowledge to robotic control. arXiv\n",
      "preprint arXiv:2307.15818 , 2023.\n",
      "T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry,\n",
      "A. Askell, et al. Language models are few-shot learners. Advances in Neural Information Processing\n",
      "CHUNK 13:\n",
      "Laird (2022). B: Soar’s decision procedure uses productions to select and implement actions. These actions\n",
      "may beinternal (such as modifying the agent’s memory) or external (such as a motor command).\n",
      "simple production system implementing a thermostat agent:\n",
      "(temperature >70◦)∧(temperature <72◦)→stop\n",
      "temperature <32◦→call for repairs; turn on electric heater\n",
      "(temperature <70◦)∧(furnace off)→turn on furnace\n",
      "(temperature >72◦)∧(furnace on)→turn off furnace\n",
      "Following this work, production systems were adopted by the AI community. The resulting agents con-\n",
      "tained large production systems connected to external sensors, actuators, and knowledge bases – requiring\n",
      "correspondingly sophisticated control flow. AI researchers defined “cognitive architectures” that mimicked\n",
      "CHUNK 14:\n",
      "schemes. Modern LLMs are trained on enormous amounts of data, which helps them accumulate knowledge\n",
      "from a large number of input-output combinations and successfully generate human-like text (Andreas, 2022).\n",
      "Unexpectedly, training these models on internet-scale text also made them useful for many tasks beyond\n",
      "generating text, such as writing code (Li et al., 2022b; Rozière et al., 2023; Li et al., 2023c), modeling\n",
      "proteins (Meier et al., 2021), and acting in interactive environments (Yao et al., 2022b; Nakano et al., 2021).\n",
      "The latter has led to the rise of “language agents” – systems that use LLMs as a core computation unit to\n",
      "reason, plan, and act – with applications in areas such as robotics (Ahn et al., 2022), manufacturing (Xia\n",
      "CHUNK 15:\n",
      "to capture human problem solving (Newell, 1967; Newell and Simon, 1972). Productions were generalized\n",
      "beyond string rewriting to logical operations: preconditions that could be checked against the agent’s goals\n",
      "and world state, and actionsthat should be taken if the preconditions were satisfied. In their landmark book\n",
      "Human Problem Solving (Newell and Simon, 1972), Allen Newell and Herbert Simon gave the example of a\n",
      "3 Published in Transactions on Machine Learning Research (02/2024)\n",
      "/gid00034 /gid00035\n",
      "Action \n",
      "SelectionProposal and\n",
      "Evalutation\n",
      "ApplicationInput\n",
      "Output\n",
      "Figure 2: Cognitive architectures augment a production system with sensory groundings, long-term memory,\n",
      "and a decision procedure for selecting actions. A: The Soar architecture, reproduced with permission from\n",
      "        \n",
      "==================================================================================================== \n",
      "\n",
      "Message 7 - HUMAN:  What pairs well with my favorite food\n",
      "==================================================================================================== \n",
      "\n",
      "Message 8 - AI:  Lava cakes, your favorite food, pair wonderfully with a variety of sides and accompaniments. Some popular pairings include:\n",
      "\n",
      "1. **Ice Cream:** Vanilla ice cream is a classic choice to complement the rich, molten chocolate of a lava cake. The contrast of hot and cold creates a delightful combination.\n",
      "\n",
      "2. **Fresh Berries:** Strawberries, raspberries, or blueberries add a fresh and slightly tart contrast to the sweetness of the lava cake.\n",
      "\n",
      "3. **Whipped Cream:** A dollop of whipped cream can add a light and airy texture that balances the density of the cake.\n",
      "\n",
      "4. **Espresso or Coffee:** The bold flavors of coffee or espresso can enhance the chocolate flavors of the lava cake.\n",
      "\n",
      "5. **Caramel or Raspberry Sauce:** Drizzling a sauce over the top can add an extra layer of flavor and make the dessert feel even more indulgent.\n",
      "\n",
      "These pairings can elevate your lava cake experience and make it even more enjoyable!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(output['messages'])):\n",
    "    print(\"=\"*100, f\"\\n\\nMessage {i+1} - {output['messages'][i].type.upper()}: \", output['messages'][i].content)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e0e7a5-59d6-4815-ab1c-d818768104bd",
   "metadata": {},
   "source": [
    "---\n",
    "**Check Out an Example LangSmith Trace**\n",
    "\n",
    "https://smith.langchain.com/public/93f5d5c8-67e8-473b-8e51-648291c2d79a/r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f8e91-d802-49b2-be6b-df87031e87a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
